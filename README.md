# Leveraging Domain Requirements in Concept Based Models via Differentiable Fuzzy Logic

## üß† Overview

This repository provides an implementation of the paper *"Leveraging Domain Requirements in Concept Based Models via Differentiable Fuzzy Logic"*.  The goal of this project is to provide full access to the research results, by following the principles of transparency, reproducibility and replicability.

> **Abstract:**  
> When designing machine learning (ML) enabled software systems, it is often assumed that the training dataset implicitly captures the full domain requirements stated by the system's specification. Guaranteeing this assumption is challenging, as models frequently learn spurious correlations rather than the true underlying domain logic, leading to unreliable system behavior. Prior work addresses this by integrating domain requirements directly into the model's loss function via Fuzzy First-Order Logic (FOL) constraints, \ie differentiable mathematical expressions derived from human-readable domain rules. However, the expressiveness and hence effectiveness of these approaches are often limited, as they must directly map complex logic onto abstract features or final labels, lacking a semantically meaningful intermediate representation for precise control. We resolve this limitation using the Fuzzy Concept Bottleneck Model (ReqAware). By leveraging the CBM's intermediate layer of human-interpretable concepts, we can specify and translate complex domain requirements via differentiable fuzzy logic constraints. This concept-based approach offers flexibility and precision in enforcing knowledge, transforming the interpretability layer into a verifiable, logically consistent interface. We evaluate our approach in the traffic sign domain using the \gls{gtsrb} dataset by eliciting a set of domain requirements and training the \gls{cbm} using them. We demonstrate how our approach can improve the \gls{cbm}'s predictive performance and its satisfaction of the requirements.

---

## üèóÔ∏è Repository Structure

```
<project-root>/
‚îú‚îÄ‚îÄ files/                         # FOlder for experiment configurations and models
‚îÇ   ‚îú‚îÄ‚îÄ configs                    # stores yaml files with hyperparameters for experiments
‚îÇ   ‚îî‚îÄ‚îÄ models                     # stores trained models saved for reproducibility purposes
‚îú‚îÄ‚îÄ Makefile                       # Makefile for convenience
‚îú‚îÄ‚îÄ notebooks/                     # Graphical results and analysis
‚îÇ   ‚îú‚îÄ‚îÄ RQ1.ipynb                  # Notebook for reproducing RQ1 results
‚îÇ   ‚îî‚îÄ‚îÄ RQ2_3.ipynb                # Notebook for reproducing RQ2 and RQ3 results
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ src/                           # Code base used to obtain the results
    ‚îú‚îÄ‚îÄ experiments/               # stores experiments logs and results
    ‚îÇ   ‚îî‚îÄ‚îÄ RQ                     # results for the research questions
    ‚îÇ       ‚îú‚îÄ‚îÄ Results/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ plots/         # plots used in the paper
    ‚îú‚îÄ‚îÄ config/                    # Code responsible for reading and parsing yaml files into usable config objects
    ‚îú‚îÄ‚îÄ data_access/               # Code for handling datasets
    ‚îÇ   ‚îú‚îÄ‚îÄ concepts/              # Store classes used for reading concept aware datasets
    ‚îÇ   ‚îú‚îÄ‚îÄ datasets/              # Factory pattern for reading datasets
    ‚îÇ   ‚îú‚îÄ‚îÄ preprocess/            # Functions for augmenting and enhancing images
    ‚îÇ   ‚îî‚îÄ‚îÄ registry.py            # Maps dataset names with their implementation
    ‚îú‚îÄ‚îÄ models                     # Code for implementing the models
    ‚îÇ   ‚îú‚îÄ‚îÄ architectures/         # Backbone architectures
    ‚îÇ   ‚îú‚îÄ‚îÄ loss/                  # Implementation of fuzzy rules as loss funtions
    ‚îÇ   ‚îú‚îÄ‚îÄ registries/            # diverse mappings
    ‚îÇ   ‚îú‚îÄ‚îÄ trainer/               # Code for handling the training of models
    ‚îÇ   ‚îî‚îÄ‚îÄ utils/                 # Utility functions
    ‚îú‚îÄ‚îÄ rule_eval/                 # Code for checking rule violations
    ‚îú‚îÄ‚îÄ hyperparameter_opt.py      # Functions used in the hyperparameter tuning proccess
    ‚îú‚îÄ‚îÄ reproduce_experiments.py   # Code used to generate the models used in the evaluation
    ‚îú‚îÄ‚îÄ collect_results.py         # after generating the models, this code collects the results.
    ‚îú‚îÄ‚îÄ train_cbm.py               # Script for training a CBM
    ‚îú‚îÄ‚îÄ train.py                   # Script for training a baseline CNN
    ‚îî‚îÄ‚îÄ utils/                     # Utility functions
````

---

## ‚öôÔ∏è Installation

1. Clone this repository

2. Create a virtual environment and install dependencies:

   ```bash
   python -m venv venv
   source venv/bin/activate       # (Linux/Mac)
   venv\Scripts\activate          # (Windows)
   pip install -r requirements.txt
   ```

3. Download or prepare datasets
  - [German Traffic Sign Benchmark (GTSRB)](https://benchmark.ini.rub.de/gtsrb_dataset.html)
  - [Belgium Traffic Sign Dataset (BTSD)](https://btsd.ethz.ch/shareddata/)
---

## üöÄ Usage

### Train a Baseline CNN model

```bash
python src/train.py --config_file /path/to/config.yaml
```

### Train a ReqAware model

```bash
python src/train_cbm.py --config_file /path/to/config.yaml
```

### Evaluate the model

```bash
make reproduce-experiments
```
Afterwards, run files Notebooks/RQ1.ipynb and Notebooks/RQ2_3.ipynb

---


## üîç Extended Work (Optional)

This codebase can be easily tweaked to work with new datasets and new sets of requirements. For example:

- New datasets can be created by developing a data factory to handle its reading and adding them to the registry.
- New requirements can be implemented by using the Fuzzy transformations inside src/models/loss/fuzzy_transformations.py and by placing them in custom_rules.py 

---

## üì¶ Dependencies

* Python >= 3.8
* torch == 2.9.0
* NumPy == 1.23.5 

See [`requirements.txt`](./requirements.txt) for the full list.

---
