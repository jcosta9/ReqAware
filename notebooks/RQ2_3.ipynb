{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59355f2f",
   "metadata": {},
   "source": [
    "#### RQ3: How does the induction of domain requirements impact the robustness of the Concept Bottleneck Model?\n",
    "The aim of this RQ is to show that the model becomes more robust and logical with respect to images that it has not been trained on. For this purpose we use images from the GTSRB test set that have been morphed, images from the Belgium Traffic Sign dataset that cannot be directly mapped to the GTSRB i.e., unseen traffic signs and images from a far OOD dataset the CIFAR-10 to evaluate what impact the introduction of domain requirements has for images that have none of the characteristics of traffic signs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673addd1",
   "metadata": {},
   "source": [
    "#### Setting up configs and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# changing the cwd to be source for all the imports to continue working\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from models.architectures import CBMSequentialEfficientNetFCN\n",
    "from config import load_config\n",
    "from models.trainer.cbm_trainer import CBMTrainer\n",
    "from rule_eval import construct_full_graph\n",
    "import pandas as pd\n",
    "\n",
    "# Import utility functions\n",
    "from analysis_utils import (\n",
    "    get_dataset_predictions,\n",
    "    analyze_fuzzy_loss_single_model,\n",
    "    compare_fuzzy_losses,\n",
    "    analyze_rule_violations,\n",
    "    compare_violations,\n",
    "    print_fuzzy_loss_results,\n",
    "    print_violation_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(\"../files/configs/\")\n",
    "models_path = Path(\"../files/models/\")\n",
    "data_path = Path(\"../../../data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc39154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configs and model loading\n",
    "baseline_cbm_config = load_config(config_path / \"GTSRB_CBM_config_loading.yaml\")\n",
    "baseline_cbm = CBMSequentialEfficientNetFCN(baseline_cbm_config)\n",
    "\n",
    "fuzzy_cbm_config = load_config(config_path / \"GTSRB_CBM_config_best_trial_loading.yaml\")\n",
    "fuzzy_cbm = CBMSequentialEfficientNetFCN(fuzzy_cbm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model paths for loading models\n",
    "baseline_cbm_concept_predictor_path = Path(\"../notebooks/best_acc_models/20251016_224601_s907_baseline_concept_predictor_best_model.pt\")\n",
    "baseline_cbm_label_predictor_path = Path(\"../experiments/baseline_cbm/models/20251001_083717_label_predictor_best_model.pt\")\n",
    "fuzzy_cbm_concept_predictor_path = Path(\"../notebooks/best_acc_models/20251020_223819_s269_concept_predictor_best_model.pt\")\n",
    "fuzzy_cbm_label_precitor_path = Path(\"../experiments/fuzzy_CBM/models/20251001_113637_label_predictor_best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac3ded21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Baseline CBM: ../notebooks/best_acc_models\n",
      "  Fuzzy CBM:    ../notebooks/best_acc_models\n"
     ]
    }
   ],
   "source": [
    "# Load the baseline model components weights\n",
    "baseline_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_concept_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "baseline_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_label_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Load the fuzzy model components weights\n",
    "fuzzy_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_concept_predictor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "fuzzy_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_label_precitor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Set models to evaluation mode\n",
    "baseline_cbm.eval()\n",
    "fuzzy_cbm.eval()\n",
    "\n",
    "print(f\"  Baseline CBM: {baseline_cbm_concept_predictor_path.parent}\")\n",
    "print(f\"  Fuzzy CBM:    {fuzzy_cbm_concept_predictor_path.parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d851dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders()\n",
    "train_loader = dataset_factory.train_dataloader\n",
    "val_loader = dataset_factory.val_dataloader\n",
    "test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "511c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Trainers and Get Fuzzy Loss Function\n",
    "baseline_cbm_trainer = CBMTrainer(\n",
    "    config=baseline_cbm_config,\n",
    "    model=baseline_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "fuzzy_cbm_trainer = CBMTrainer(\n",
    "    config=fuzzy_cbm_config,\n",
    "    model=fuzzy_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "# Get the fuzzy loss function\n",
    "neutral_fuzzy_loss = fuzzy_cbm_trainer.concept_predictor_trainer.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5200784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rule checker\n",
    "rule_checker = construct_full_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127509d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1d97ba",
   "metadata": {},
   "source": [
    "#### Loading the GTSRB test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1b87ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GTSRB Dataset\n",
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders()\n",
    "\n",
    "test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490520fc",
   "metadata": {},
   "source": [
    "#### Loading the morphed GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dc08053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the morphed GTSRB dataset\n",
    "from data_access.datasets.GTSRBFactory import reicnn_transform_TRAIN\n",
    "\n",
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders(train_transform=reicnn_transform_TRAIN, test_transform=reicnn_transform_TRAIN)\n",
    "morphed_gtsrb_test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665126d7",
   "metadata": {},
   "source": [
    "#### Loading the unmapped BTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "843e5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the BTS and filtering out the signs that cannot be mapped \n",
    "# fixing seed to ensuring reproducibility\n",
    "from config.dataset_config import ConceptDatasetConfig\n",
    "\n",
    "# Create BTS dataset configuration\n",
    "bts_config = ConceptDatasetConfig(\n",
    "    name=\"bts\",\n",
    "    n_labels=62,  \n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle_dataset=False,\n",
    "    pin_memory=True,\n",
    "    data_path=Path(\"../data/raw/BTSD/\"),\n",
    "    val_split=0.2\n",
    "\n",
    ")\n",
    "# Resolve the configuration to validate paths and load concept map\n",
    "bts_config.resolve()\n",
    "\n",
    "# Create the dataset factory\n",
    "from data_access.datasets import GTSRBFactory\n",
    "\n",
    "bts_factory = GTSRBFactory(config=bts_config, seed=fuzzy_cbm_config.seed)\n",
    "bts_factory.set_dataloaders()\n",
    "\n",
    "# Access the dataloaders\n",
    "bts_test_loader = bts_factory.test_dataloader\n",
    "bts_train_loader = bts_factory.train_dataloader\n",
    "bts_val_loader = bts_factory.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc2f9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of each sign in the GTSRB and how it is mapped to the BTS. If there is an unambiguous mapping, the value is set to the BST label, otherwise it is -1. \n",
    "labels_id_GTS_to_BTS = [-1,-1,-1,-1,-1,-1,-1,-1,-1,31,-1,17,61,19,21,28,25,22,13,3,4,5,0,2,16,10,-1,-1,-1,8,-1,-1,-1,-1,-1,34,-1,-1,35,-1,37,-1,-1]\n",
    "mapping_BTS_to_GTSRB = {i : labels_id_GTS_to_BTS.index(i) for i in labels_id_GTS_to_BTS if i != -1}\n",
    "Belgium_ID_to_Name = {0: \"Bumpy road\",1: \"Bump\",2: \"Slippery road\",3: \"Bend to The left\",4: \"Bend to The right\",5: \"Double curves first to the left\",6: \"Double curves first to the right\",7: \"School zone\",8: \"Bikes can be cross\",9: \"Domestic animal crossing\",10: \"Roadworks\",11: \"Traffic light\",12: \"Gated railroad crossing ahead\",13: \"Caution\",14: \"Road narrows\",15: \"Road narrows on the left\",16: \"Road narrows on the right\",17: \"Intersection with priority\",18: \"Intersection with priority to the right\",19: \"Yield\",20: \"Yield to incoming traffic\",21: \"Stop\",22: \"No entry\",23: \"No entry for cyclists\",24: \"No vehicle over 2t\",25: \"No entry for trucks\",26: \"Width limit\",27: \"Height limit\",28: \"No vehicles\",29: \"No left turn\",30: \"No right turn\",31: \"No overtaking\",32: \"Speed limit\",33: \"Shared path for pedestrians and cyclists\",34: \"Ahead only\",35: \"Right only\",36: \"Ahead and right only\",37: \"Roundabout\",38: \"Cycleway\",39: \"Segregated path for pedestrians and cyclists\",40: \"No parking\",41: \"No stopping\",42: \"No parking from the 1st till 15th day of the month\",43: \"No parking from the 16th till last day of the month\",44: \"Priority over oncoming traffic\",45: \"Parking permitted\",46: \"Parking for disabled\",47: \"Parking reserved for motorcycles, cars, vans (< 3.5t) and minibusses\",48: \"Parking reserved for trucks\",49: \"Parking reserved for coaches\",50: \"Parking mandatory on the verge or sidewalk\",51: \"Start of a living street\",52: \"End of living street\",53: \"One-way road\",54: \"Dead end\",55: \"End of roadworks\",56: \"Pedestrian crossing\",57: \"Cyclist and moped crossing\",58: \"Parking lot\",59: \"Hump\",60: \"End of priority road\",61: \"Priority road\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c164b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering BTS datasets to only include unambiguous mappings to GTSRB...\n",
      "Valid BTS labels: [0, 2, 3, 4, 5, 8, 10, 13, 16, 17, 19, 21, 22, 25, 28, 31, 34, 35, 37, 61]\n",
      "Number of valid labels: 20\n",
      "\n",
      "Original BTS train size: 3660\n",
      "Valid indices found: 2326\n",
      "Filtered BTS train size: 2326\n",
      "\n",
      "Filtered dataloader created successfully!\n",
      "Dataloader ready: bts_train_loader_filtered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Get labels that have unambiguous mapping to GTSRB\n",
    "valid_bts_labels = [i for i in labels_id_GTS_to_BTS if i != -1]\n",
    "\n",
    "# Filter the BTS datasets\n",
    "print(\"Filtering BTS datasets to only include unambiguous mappings to GTSRB...\")\n",
    "print(f\"Valid BTS labels: {sorted(valid_bts_labels)}\")\n",
    "print(f\"Number of valid labels: {len(valid_bts_labels)}\")\n",
    "\n",
    "# Filter train dataset - get valid indices\n",
    "valid_indices = []\n",
    "for idx in range(len(bts_factory.train_dataset)):\n",
    "    try:\n",
    "        _, _, label_data = bts_factory.train_dataset[idx]\n",
    "        # Handle both tuple and single label formats\n",
    "        if isinstance(label_data, tuple):\n",
    "            label = label_data[0].item() if hasattr(label_data[0], 'item') else label_data[0]\n",
    "        else:\n",
    "            label = label_data.item() if hasattr(label_data, 'item') else label_data\n",
    "        \n",
    "        if label not in valid_bts_labels:\n",
    "            valid_indices.append(idx)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not process index {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nOriginal BTS train size: {len(bts_factory.train_dataset)}\")\n",
    "print(f\"Valid indices found: {len(valid_indices)}\")\n",
    "\n",
    "# Create filtered dataset using Subset\n",
    "bts_train_filtered = Subset(bts_factory.train_dataset, valid_indices)\n",
    "print(f\"Filtered BTS train size: {len(bts_train_filtered)}\")\n",
    "\n",
    "# Create dataloader with filtered dataset\n",
    "bts_train_loader_filtered = DataLoader(\n",
    "    bts_train_filtered,\n",
    "    batch_size=bts_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=bts_config.pin_memory,\n",
    ")\n",
    "\n",
    "print(\"\\nFiltered dataloader created successfully!\")\n",
    "print(f\"Dataloader ready: bts_train_loader_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af119166",
   "metadata": {},
   "source": [
    "#### Loading the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcc3d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from data_access.datasets.CIFAR10Factory import CIFAR10Factory\n",
    "\n",
    "cifar10_config = ConceptDatasetConfig(\n",
    "    name=\"cifar10\",\n",
    "    n_labels=10, \n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle_dataset=False,\n",
    "    pin_memory=True,\n",
    "    data_path=Path(\"../data/raw/CIFAR10/\"),\n",
    "    val_split=0.2\n",
    ")\n",
    "cifar10_config.resolve()\n",
    "\n",
    "cifar10_factory = CIFAR10Factory(config=cifar10_config, seed=fuzzy_cbm_config.seed)\n",
    "cifar10_factory.set_dataloaders()\n",
    "\n",
    "# Access the dataloaders\n",
    "cifar10_test_loader = cifar10_factory.test_dataloader\n",
    "cifar10_train_loader = cifar10_factory.train_dataloader\n",
    "cifar10_val_loader = cifar10_factory.val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f40111",
   "metadata": {},
   "source": [
    "#### Printing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff41e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RQ2/3: ROBUSTNESS ANALYSIS ON OUT-OF-DISTRIBUTION DATASETS\n",
      "================================================================================\n",
      "\n",
      "Analyzing three datasets:\n",
      "  0. GTSRB (ID - Baseline)\n",
      "  1. Morphed GTSRB (Near OOD - data augmentation)\n",
      "  2. Filtered BTS  (Near OOD - different traffic signs)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE ANALYSIS: MORPHED GTSRB, FILTERED BTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RQ2/3: ROBUSTNESS ANALYSIS ON OUT-OF-DISTRIBUTION DATASETS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAnalyzing three datasets:\")\n",
    "print(\"  0. GTSRB (ID - Baseline)\")\n",
    "print(\"  1. Morphed GTSRB (Near OOD - data augmentation)\")\n",
    "print(\"  2. Filtered BTS  (Near OOD - different traffic signs)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Storage for all results\n",
    "all_predictions = {}\n",
    "all_fuzzy_metrics = {}\n",
    "all_violations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "775fcbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYZING GTSRB DATASET (In-Distribution)\n",
      "================================================================================\n",
      "\n",
      "Getting predictions from both models on GTSRB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting GTSRB (Baseline) predictions: 100%|██████████| 99/99 [00:13<00:00,  7.19it/s]\n",
      "Getting GTSRB (Fuzzy) predictions: 100%|██████████| 99/99 [00:13<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FUZZY LOSS ANALYSIS - GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on GTSRB:\n",
      "  Standard BCE Loss:    0.0003751071\n",
      "  Fuzzy Rules Loss:     0.0137938075\n",
      "  Total Loss:           0.0141689146\n",
      "\n",
      "Fuzzy CBM on GTSRB:\n",
      "  Standard BCE Loss:    0.0002976162\n",
      "  Fuzzy Rules Loss:     0.0130780460\n",
      "  Total Loss:           0.0133756623\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.0007157614\n",
      "    Relative: 5.19%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RULE VIOLATION ANALYSIS - GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 17\n",
      "  Violation rate:          0.13%\n",
      "\n",
      "Fuzzy CBM on GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 21\n",
      "  Violation rate:          0.17%\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: -0.03 percentage points\n",
      "    Relative: -23.53%\n",
      "\n",
      "================================================================================\n",
      "PER-RULE FUZZY LOSS COMPARISON - GTSRB\n",
      "================================================================================\n",
      "\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "     at_most_one_border_colour   1.156950e-05    0.000000e+00  1.156950e-05     100.000000\n",
      "no_symbols_exactly_two_colours   8.708388e-04    3.486725e-04  5.221663e-04      59.961305\n",
      "           at_most_one_warning   1.229602e-02    1.211789e-02  1.781275e-04       1.448660\n",
      "      warning_sign_exclusivity   4.653594e-04    4.614065e-04  3.952882e-06       0.849426\n",
      "             exactly_one_shape   7.501225e-05    7.501248e-05 -2.328306e-10      -0.000310\n",
      "       exactly_one_main_colour   7.500465e-05    7.501285e-05 -8.207280e-09      -0.010942\n",
      "    warning_implies_main_white   2.911803e-09    3.345977e-08 -3.054797e-08   -1049.108593\n",
      "    warning_implies_border_red   3.633854e-10    1.664966e-08 -1.628627e-08   -4481.817932\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 0. GTSRB ANALYSIS (In-Distribution - for comparison baseline)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING GTSRB DATASET (In-Distribution)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from both models\n",
    "print(\"\\nGetting predictions from both models on GTSRB...\")\n",
    "baseline_preds_gtsrb = get_dataset_predictions(\n",
    "    baseline_cbm, test_loader, baseline_cbm_config.device, \"GTSRB (Baseline)\"\n",
    ")\n",
    "fuzzy_preds_gtsrb = get_dataset_predictions(\n",
    "    fuzzy_cbm, test_loader, fuzzy_cbm_config.device, \"GTSRB (Fuzzy)\"\n",
    ")\n",
    "\n",
    "# FUZZY LOSS ANALYSIS - GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_fuzzy_gtsrb = analyze_fuzzy_loss_single_model(\n",
    "    baseline_preds_gtsrb['logits'], \n",
    "    baseline_preds_gtsrb['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Baseline CBM', \n",
    "    'GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_fuzzy_gtsrb = analyze_fuzzy_loss_single_model(\n",
    "    fuzzy_preds_gtsrb['logits'], \n",
    "    fuzzy_preds_gtsrb['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Fuzzy CBM', \n",
    "    'GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_comparison_gtsrb = compare_fuzzy_losses(baseline_fuzzy_gtsrb, fuzzy_fuzzy_gtsrb)\n",
    "\n",
    "print_fuzzy_loss_results(baseline_fuzzy_gtsrb)\n",
    "print_fuzzy_loss_results(fuzzy_fuzzy_gtsrb, fuzzy_comparison_gtsrb)\n",
    "\n",
    "# RULE VIOLATION ANALYSIS - GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_viols_gtsrb = analyze_rule_violations(\n",
    "    baseline_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "fuzzy_viols_gtsrb = analyze_rule_violations(\n",
    "    fuzzy_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "violation_comparison_gtsrb = compare_violations(baseline_viols_gtsrb, fuzzy_viols_gtsrb)\n",
    "\n",
    "print_violation_results(baseline_viols_gtsrb)\n",
    "print_violation_results(fuzzy_viols_gtsrb, violation_comparison_gtsrb)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE FUZZY LOSS COMPARISON - GTSRB\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + fuzzy_comparison_gtsrb['rule_comparison'].to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "all_predictions['gtsrb_baseline'] = baseline_preds_gtsrb\n",
    "all_predictions['gtsrb_fuzzy'] = fuzzy_preds_gtsrb\n",
    "all_fuzzy_metrics['GTSRB_baseline'] = baseline_fuzzy_gtsrb\n",
    "all_fuzzy_metrics['GTSRB_fuzzy'] = fuzzy_fuzzy_gtsrb\n",
    "all_violations['GTSRB_baseline'] = baseline_viols_gtsrb\n",
    "all_violations['GTSRB_fuzzy'] = fuzzy_viols_gtsrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4f2befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYZING MORPHED GTSRB DATASET (Near OOD - Augmented)\n",
      "================================================================================\n",
      "\n",
      "Getting predictions from both models on Morphed GTSRB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Morphed GTSRB (Baseline) predictions: 100%|██████████| 99/99 [00:13<00:00,  7.15it/s]\n",
      "Getting Morphed GTSRB (Fuzzy) predictions: 100%|██████████| 99/99 [00:14<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FUZZY LOSS ANALYSIS - MORPHED GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Morphed GTSRB:\n",
      "  Standard BCE Loss:    0.0081922812\n",
      "  Fuzzy Rules Loss:     0.0293253567\n",
      "  Total Loss:           0.0375176379\n",
      "\n",
      "Fuzzy CBM on Morphed GTSRB:\n",
      "  Standard BCE Loss:    0.0070346040\n",
      "  Fuzzy Rules Loss:     0.0172272548\n",
      "  Total Loss:           0.0242618588\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.0120981019\n",
      "    Relative: 41.25%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RULE VIOLATION ANALYSIS - MORPHED GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Morphed GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 732\n",
      "  Violation rate:          5.80%\n",
      "\n",
      "Fuzzy CBM on Morphed GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 554\n",
      "  Violation rate:          4.39%\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 1.41 percentage points\n",
      "    Relative: 24.32%\n",
      "\n",
      "================================================================================\n",
      "PER-RULE FUZZY LOSS COMPARISON - MORPHED GTSRB\n",
      "================================================================================\n",
      "\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "     at_most_one_border_colour   3.267445e-03    9.438582e-12  3.267445e-03     100.000000\n",
      "no_symbols_exactly_two_colours   1.799850e-02    8.990700e-03  9.007803e-03      50.047512\n",
      "    warning_implies_border_red   7.231228e-07    3.672269e-07  3.558959e-07      49.216523\n",
      "    warning_implies_main_white   9.363687e-07    5.846399e-07  3.517288e-07      37.563065\n",
      "      warning_sign_exclusivity   3.644418e-04    3.308335e-04  3.360829e-05       9.221853\n",
      "       exactly_one_main_colour   7.541812e-05    7.526257e-05  1.555527e-07       0.206254\n",
      "             exactly_one_shape   7.532208e-05    7.524533e-05  7.674680e-08       0.101892\n",
      "           at_most_one_warning   7.542567e-03    7.754261e-03 -2.116943e-04      -2.806661\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. MORPHED GTSRB ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING MORPHED GTSRB DATASET (Near OOD - Augmented)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from both models\n",
    "print(\"\\nGetting predictions from both models on Morphed GTSRB...\")\n",
    "baseline_preds_morphed = get_dataset_predictions(\n",
    "    baseline_cbm, morphed_gtsrb_test_loader, baseline_cbm_config.device, \"Morphed GTSRB (Baseline)\"\n",
    ")\n",
    "fuzzy_preds_morphed = get_dataset_predictions(\n",
    "    fuzzy_cbm, morphed_gtsrb_test_loader, fuzzy_cbm_config.device, \"Morphed GTSRB (Fuzzy)\"\n",
    ")\n",
    "\n",
    "# FUZZY LOSS ANALYSIS - Morphed GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - MORPHED GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_fuzzy_morphed = analyze_fuzzy_loss_single_model(\n",
    "    baseline_preds_morphed['logits'], \n",
    "    baseline_preds_morphed['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Baseline CBM', \n",
    "    'Morphed GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_fuzzy_morphed = analyze_fuzzy_loss_single_model(\n",
    "    fuzzy_preds_morphed['logits'], \n",
    "    fuzzy_preds_morphed['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Fuzzy CBM', \n",
    "    'Morphed GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_comparison_morphed = compare_fuzzy_losses(baseline_fuzzy_morphed, fuzzy_fuzzy_morphed)\n",
    "\n",
    "print_fuzzy_loss_results(baseline_fuzzy_morphed)\n",
    "print_fuzzy_loss_results(fuzzy_fuzzy_morphed, fuzzy_comparison_morphed)\n",
    "\n",
    "# RULE VIOLATION ANALYSIS - Morphed GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - MORPHED GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_viols_morphed = analyze_rule_violations(\n",
    "    baseline_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "fuzzy_viols_morphed = analyze_rule_violations(\n",
    "    fuzzy_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "violation_comparison_morphed = compare_violations(baseline_viols_morphed, fuzzy_viols_morphed)\n",
    "\n",
    "print_violation_results(baseline_viols_morphed)\n",
    "print_violation_results(fuzzy_viols_morphed, violation_comparison_morphed)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE FUZZY LOSS COMPARISON - MORPHED GTSRB\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + fuzzy_comparison_morphed['rule_comparison'].to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "all_predictions['morphed_baseline'] = baseline_preds_morphed\n",
    "all_predictions['morphed_fuzzy'] = fuzzy_preds_morphed\n",
    "all_fuzzy_metrics['Morphed GTSRB_baseline'] = baseline_fuzzy_morphed\n",
    "all_fuzzy_metrics['Morphed GTSRB_fuzzy'] = fuzzy_fuzzy_morphed\n",
    "all_violations['Morphed GTSRB_baseline'] = baseline_viols_morphed\n",
    "all_violations['Morphed GTSRB_fuzzy'] = fuzzy_viols_morphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed51ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYZING FILTERED BTS DATASET (Near OOD - Different Traffic Signs)\n",
      "================================================================================\n",
      "\n",
      "Getting predictions from both models on Filtered BTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Filtered BTS (Baseline) predictions: 100%|██████████| 37/37 [00:02<00:00, 13.47it/s]\n",
      "Getting Filtered BTS (Fuzzy) predictions: 100%|██████████| 37/37 [00:02<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FUZZY LOSS ANALYSIS - FILTERED BTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Filtered BTS:\n",
      "  Standard BCE Loss:    0.0133687975\n",
      "  Fuzzy Rules Loss:     0.1319774687\n",
      "  Total Loss:           0.1453462662\n",
      "\n",
      "Fuzzy CBM on Filtered BTS:\n",
      "  Standard BCE Loss:    0.0123623293\n",
      "  Fuzzy Rules Loss:     0.1152333990\n",
      "  Total Loss:           0.1275957283\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.0167440698\n",
      "    Relative: 12.69%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RULE VIOLATION ANALYSIS - FILTERED BTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Filtered BTS:\n",
      "  Total samples:           2326\n",
      "  Samples with violations: 567\n",
      "  Violation rate:          24.38%\n",
      "\n",
      "Fuzzy CBM on Filtered BTS:\n",
      "  Total samples:           2326\n",
      "  Samples with violations: 353\n",
      "  Violation rate:          15.18%\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 9.20 percentage points\n",
      "    Relative: 37.74%\n",
      "\n",
      "================================================================================\n",
      "PER-RULE FUZZY LOSS COMPARISON - FILTERED BTS\n",
      "================================================================================\n",
      "\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "     at_most_one_border_colour   1.701329e-04    0.000000e+00  1.701329e-04     100.000000\n",
      "no_symbols_exactly_two_colours   7.186738e-02    3.551781e-02  3.634958e-02      50.578682\n",
      "    warning_implies_main_white   5.903320e-07    3.651361e-07  2.251959e-07      38.147326\n",
      "             exactly_one_shape   7.555744e-05    7.524015e-05  3.172900e-07       0.419932\n",
      "       exactly_one_main_colour   7.609694e-05    7.607189e-05  2.505112e-08       0.032920\n",
      "      warning_sign_exclusivity   3.404634e-04    4.074251e-04 -6.696171e-05     -19.667818\n",
      "           at_most_one_warning   5.944721e-02    7.915553e-02 -1.970833e-02     -33.152656\n",
      "    warning_implies_border_red   2.583039e-08    9.563138e-07 -9.304834e-07   -3602.281845\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. FILTERED BTS ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING FILTERED BTS DATASET (Near OOD - Different Traffic Signs)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from both models\n",
    "print(\"\\nGetting predictions from both models on Filtered BTS...\")\n",
    "baseline_preds_bts = get_dataset_predictions(\n",
    "    baseline_cbm, bts_train_loader_filtered, baseline_cbm_config.device, \"Filtered BTS (Baseline)\"\n",
    ")\n",
    "fuzzy_preds_bts = get_dataset_predictions(\n",
    "    fuzzy_cbm, bts_train_loader_filtered, fuzzy_cbm_config.device, \"Filtered BTS (Fuzzy)\"\n",
    ")\n",
    "\n",
    "# FUZZY LOSS ANALYSIS - BTS\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - FILTERED BTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_fuzzy_bts = analyze_fuzzy_loss_single_model(\n",
    "    baseline_preds_bts['logits'], \n",
    "    baseline_preds_bts['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Baseline CBM', \n",
    "    'Filtered BTS'\n",
    ")\n",
    "\n",
    "fuzzy_fuzzy_bts = analyze_fuzzy_loss_single_model(\n",
    "    fuzzy_preds_bts['logits'], \n",
    "    fuzzy_preds_bts['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Fuzzy CBM', \n",
    "    'Filtered BTS'\n",
    ")\n",
    "\n",
    "fuzzy_comparison_bts = compare_fuzzy_losses(baseline_fuzzy_bts, fuzzy_fuzzy_bts)\n",
    "\n",
    "print_fuzzy_loss_results(baseline_fuzzy_bts)\n",
    "print_fuzzy_loss_results(fuzzy_fuzzy_bts, fuzzy_comparison_bts)\n",
    "\n",
    "# RULE VIOLATION ANALYSIS - BTS\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - FILTERED BTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_viols_bts = analyze_rule_violations(\n",
    "    baseline_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "fuzzy_viols_bts = analyze_rule_violations(\n",
    "    fuzzy_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "violation_comparison_bts = compare_violations(baseline_viols_bts, fuzzy_viols_bts)\n",
    "\n",
    "print_violation_results(baseline_viols_bts)\n",
    "print_violation_results(fuzzy_viols_bts, violation_comparison_bts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE FUZZY LOSS COMPARISON - FILTERED BTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + fuzzy_comparison_bts['rule_comparison'].to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "all_predictions['bts_baseline'] = baseline_preds_bts\n",
    "all_predictions['bts_fuzzy'] = fuzzy_preds_bts\n",
    "all_fuzzy_metrics['Filtered BTS_baseline'] = baseline_fuzzy_bts\n",
    "all_fuzzy_metrics['Filtered BTS_fuzzy'] = fuzzy_fuzzy_bts\n",
    "all_violations['Filtered BTS_baseline'] = baseline_viols_bts\n",
    "all_violations['Filtered BTS_fuzzy'] = fuzzy_viols_bts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d60a9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CROSS-DATASET PER-RULE FUZZY LOSS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "                          Rule  GTSRB Baseline  GTSRB Fuzzy  GTSRB Improvement %  Morphed Baseline  Morphed Fuzzy  Morphed Improvement %  BTS Baseline    BTS Fuzzy  BTS Improvement %\n",
      "     at_most_one_border_colour    1.156950e-05 0.000000e+00           100.000000      3.267445e-03   9.438582e-12             100.000000  1.701329e-04 0.000000e+00         100.000000\n",
      "           at_most_one_warning    1.229602e-02 1.211789e-02             1.448660      7.542567e-03   7.754261e-03              -2.806661  5.944721e-02 7.915553e-02         -33.152656\n",
      "       exactly_one_main_colour    7.500465e-05 7.501285e-05            -0.010942      7.541812e-05   7.526257e-05               0.206254  7.609694e-05 7.607189e-05           0.032920\n",
      "             exactly_one_shape    7.501225e-05 7.501248e-05            -0.000310      7.532208e-05   7.524533e-05               0.101892  7.555744e-05 7.524015e-05           0.419932\n",
      "no_symbols_exactly_two_colours    8.708388e-04 3.486725e-04            59.961305      1.799850e-02   8.990700e-03              50.047512  7.186738e-02 3.551781e-02          50.578682\n",
      "    warning_implies_border_red    3.633854e-10 1.664966e-08         -4481.817932      7.231228e-07   3.672269e-07              49.216523  2.583039e-08 9.563138e-07       -3602.281845\n",
      "    warning_implies_main_white    2.911803e-09 3.345977e-08         -1049.108593      9.363687e-07   5.846399e-07              37.563065  5.903320e-07 3.651361e-07          38.147326\n",
      "      warning_sign_exclusivity    4.653594e-04 4.614065e-04             0.849426      3.644418e-04   3.308335e-04               9.221853  3.404634e-04 4.074251e-04         -19.667818\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CROSS-DATASET PER-RULE FUZZY LOSS COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-DATASET PER-RULE FUZZY LOSS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect all rules across datasets\n",
    "all_rules = set()\n",
    "for comparison in [fuzzy_comparison_gtsrb, fuzzy_comparison_morphed, fuzzy_comparison_bts]:\n",
    "    all_rules.update(comparison['rule_comparison']['Rule'].values)\n",
    "\n",
    "# Build cross-dataset rule comparison\n",
    "cross_dataset_rules = []\n",
    "for rule in sorted(all_rules):\n",
    "    row_data = {'Rule': rule}\n",
    "    \n",
    "    # GTSRB\n",
    "    gtsrb_row = fuzzy_comparison_gtsrb['rule_comparison'][fuzzy_comparison_gtsrb['rule_comparison']['Rule'] == rule]\n",
    "    if not gtsrb_row.empty:\n",
    "        row_data['GTSRB Baseline'] = gtsrb_row.iloc[0]['Baseline Loss']\n",
    "        row_data['GTSRB Fuzzy'] = gtsrb_row.iloc[0]['Fuzzy CBM Loss']\n",
    "        row_data['GTSRB Improvement %'] = gtsrb_row.iloc[0]['Improvement %']\n",
    "    else:\n",
    "        row_data['GTSRB Baseline'] = 0.0\n",
    "        row_data['GTSRB Fuzzy'] = 0.0\n",
    "        row_data['GTSRB Improvement %'] = 0.0\n",
    "    \n",
    "    # Morphed GTSRB\n",
    "    morphed_row = fuzzy_comparison_morphed['rule_comparison'][fuzzy_comparison_morphed['rule_comparison']['Rule'] == rule]\n",
    "    if not morphed_row.empty:\n",
    "        row_data['Morphed Baseline'] = morphed_row.iloc[0]['Baseline Loss']\n",
    "        row_data['Morphed Fuzzy'] = morphed_row.iloc[0]['Fuzzy CBM Loss']\n",
    "        row_data['Morphed Improvement %'] = morphed_row.iloc[0]['Improvement %']\n",
    "    else:\n",
    "        row_data['Morphed Baseline'] = 0.0\n",
    "        row_data['Morphed Fuzzy'] = 0.0\n",
    "        row_data['Morphed Improvement %'] = 0.0\n",
    "    \n",
    "    # BTS\n",
    "    bts_row = fuzzy_comparison_bts['rule_comparison'][fuzzy_comparison_bts['rule_comparison']['Rule'] == rule]\n",
    "    if not bts_row.empty:\n",
    "        row_data['BTS Baseline'] = bts_row.iloc[0]['Baseline Loss']\n",
    "        row_data['BTS Fuzzy'] = bts_row.iloc[0]['Fuzzy CBM Loss']\n",
    "        row_data['BTS Improvement %'] = bts_row.iloc[0]['Improvement %']\n",
    "    else:\n",
    "        row_data['BTS Baseline'] = 0.0\n",
    "        row_data['BTS Fuzzy'] = 0.0\n",
    "        row_data['BTS Improvement %'] = 0.0\n",
    "    \n",
    "    cross_dataset_rules.append(row_data)\n",
    "\n",
    "df_cross_dataset_rules = pd.DataFrame(cross_dataset_rules)\n",
    "print(\"\\n\" + df_cross_dataset_rules.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb170d96",
   "metadata": {},
   "source": [
    "#### Analysing the rule violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "538f874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RULE VIOLATION ANALYSIS - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "Analyzing GTSRB (In-Distribution)...\n",
      "Analyzing Morphed GTSRB...\n",
      "Analyzing Filtered BTS...\n",
      "\n",
      "================================================================================\n",
      "OVERALL VIOLATION RATE SUMMARY - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "      Dataset     Type        Model  Violation Rate (%)  Violations  Total Samples\n",
      "        GTSRB  In-Dist Baseline CBM            0.134600          17          12630\n",
      "        GTSRB  In-Dist    Fuzzy CBM            0.166271          21          12630\n",
      "Morphed GTSRB Near OOD Baseline CBM            5.795724         732          12630\n",
      "Morphed GTSRB Near OOD    Fuzzy CBM            4.386382         554          12630\n",
      " Filtered BTS Near OOD Baseline CBM           24.376612         567           2326\n",
      " Filtered BTS Near OOD    Fuzzy CBM           15.176268         353           2326\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION COUNTS - GTSRB (In-Distribution)\n",
      "================================================================================\n",
      "\n",
      "                    Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      "no_symbols_exactly_two_colours              16               12            4      25.000000\n",
      "    warning_implies_main_white               0                0            0       0.000000\n",
      "      warning_sign_exclusivity               0                1           -1       0.000000\n",
      "             exactly_one_shape               7               10           -3     -42.857143\n",
      "       exactly_one_main_colour               4                8           -4    -100.000000\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION COUNTS - MORPHED GTSRB\n",
      "================================================================================\n",
      "\n",
      "                    Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      "no_symbols_exactly_two_colours             615              364          251      40.813008\n",
      "       exactly_one_main_colour             339              133          206      60.766962\n",
      "             exactly_one_shape             252              202           50      19.841270\n",
      "    warning_implies_main_white               1                0            1     100.000000\n",
      "      warning_sign_exclusivity               0                1           -1       0.000000\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION COUNTS - FILTERED BTS\n",
      "================================================================================\n",
      "\n",
      "                    Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      "no_symbols_exactly_two_colours             488              295          193      39.549180\n",
      "             exactly_one_shape              69               44           25      36.231884\n",
      "      warning_sign_exclusivity               2                0            2     100.000000\n",
      "    warning_implies_main_white               0                0            0       0.000000\n",
      "       exactly_one_main_colour             117              140          -23     -19.658120\n",
      "\n",
      "================================================================================\n",
      "CROSS-DATASET PER-CONSTRAINT COMPARISON - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "                    Constraint  GTSRB Baseline  GTSRB Fuzzy  GTSRB Improvement  Morphed GTSRB Baseline  Morphed GTSRB Fuzzy  Morphed GTSRB Improvement  BTS Baseline  BTS Fuzzy  BTS Improvement\n",
      "       exactly_one_main_colour               4            8                 -4                     339                  133                        206           117        140              -23\n",
      "             exactly_one_shape               7           10                 -3                     252                  202                         50            69         44               25\n",
      "no_symbols_exactly_two_colours              16           12                  4                     615                  364                        251           488        295              193\n",
      "    warning_implies_main_white               0            0                  0                       1                    0                          1             0          0                0\n",
      "      warning_sign_exclusivity               0            1                 -1                       0                    1                         -1             2          0                2\n",
      "\n",
      "================================================================================\n",
      "IMPROVEMENT ANALYSIS - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "GTSRB Dataset (In-Distribution):\n",
      "  Baseline violation rate:  0.13%\n",
      "  Fuzzy CBM violation rate: 0.17%\n",
      "  Improvement:              -0.03 percentage points\n",
      "  Relative improvement:     -23.53%\n",
      "\n",
      "Morphed GTSRB Dataset (Near OOD):\n",
      "  Baseline violation rate:  5.80%\n",
      "  Fuzzy CBM violation rate: 4.39%\n",
      "  Improvement:              1.41 percentage points\n",
      "  Relative improvement:     24.32%\n",
      "\n",
      "Filtered BTS Dataset (Near OOD):\n",
      "  Baseline violation rate:  24.38%\n",
      "  Fuzzy CBM violation rate: 15.18%\n",
      "  Improvement:              9.20 percentage points\n",
      "  Relative improvement:     37.74%\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY - RQ3 ROBUSTNESS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Violation Rate Reductions Across All Datasets:\n",
      "  1. GTSRB (In-Dist):       -0.03 pp (-23.53%)\n",
      "  2. Morphed GTSRB:         1.41 pp (+24.32%)\n",
      "  3. BTS:                   9.20 pp (+37.74%)\n",
      "\n",
      "================================================================================\n",
      "RQ3 ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RULE VIOLATION ANALYSIS WITH DETAILED PER-RULE COMPARISON - THREE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze violations for all datasets\n",
    "print(\"\\nAnalyzing GTSRB (In-Distribution)...\")\n",
    "baseline_viols_gtsrb = analyze_rule_violations(\n",
    "    baseline_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "fuzzy_viols_gtsrb = analyze_rule_violations(\n",
    "    fuzzy_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "print(\"Analyzing Morphed GTSRB...\")\n",
    "baseline_viols_morphed = analyze_rule_violations(\n",
    "    baseline_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "fuzzy_viols_morphed = analyze_rule_violations(\n",
    "    fuzzy_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "print(\"Analyzing Filtered BTS...\")\n",
    "baseline_viols_bts = analyze_rule_violations(\n",
    "    baseline_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "fuzzy_viols_bts = analyze_rule_violations(\n",
    "    fuzzy_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# OVERALL VIOLATION RATE SUMMARY - THREE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL VIOLATION RATE SUMMARY - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "violation_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Dataset': 'GTSRB',\n",
    "        'Type': 'In-Dist',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_viols_gtsrb['violation_rate'],\n",
    "        'Violations': baseline_viols_gtsrb['total_violations'],\n",
    "        'Total Samples': baseline_viols_gtsrb['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'GTSRB',\n",
    "        'Type': 'In-Dist',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_viols_gtsrb['violation_rate'],\n",
    "        'Violations': fuzzy_viols_gtsrb['total_violations'],\n",
    "        'Total Samples': fuzzy_viols_gtsrb['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Morphed GTSRB',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_viols_morphed['violation_rate'],\n",
    "        'Violations': baseline_viols_morphed['total_violations'],\n",
    "        'Total Samples': baseline_viols_morphed['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Morphed GTSRB',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_viols_morphed['violation_rate'],\n",
    "        'Violations': fuzzy_viols_morphed['total_violations'],\n",
    "        'Total Samples': fuzzy_viols_morphed['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Filtered BTS',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_viols_bts['violation_rate'],\n",
    "        'Violations': baseline_viols_bts['total_violations'],\n",
    "        'Total Samples': baseline_viols_bts['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Filtered BTS',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_viols_bts['violation_rate'],\n",
    "        'Violations': fuzzy_viols_bts['total_violations'],\n",
    "        'Total Samples': fuzzy_viols_bts['total_samples']\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + violation_summary.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# PER-CONSTRAINT ANALYSIS FOR ALL DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "# Collect all constraints across all datasets\n",
    "all_constraints = (\n",
    "    set(baseline_viols_gtsrb['constraint_counts'].keys()) |\n",
    "    set(baseline_viols_morphed['constraint_counts'].keys()) |\n",
    "    set(baseline_viols_bts['constraint_counts'].keys())\n",
    ")\n",
    "\n",
    "# GTSRB Per-Constraint\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION COUNTS - GTSRB (In-Distribution)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraint_comparison_gtsrb = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    baseline_count = baseline_viols_gtsrb['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_viols_gtsrb['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_gtsrb.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_gtsrb = pd.DataFrame(constraint_comparison_gtsrb)\n",
    "df_constraint_gtsrb = df_constraint_gtsrb.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_gtsrb.to_string(index=False))\n",
    "\n",
    "# Morphed GTSRB Per-Constraint\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION COUNTS - MORPHED GTSRB\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraint_comparison_morphed = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    baseline_count = baseline_viols_morphed['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_viols_morphed['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_morphed.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_morphed = pd.DataFrame(constraint_comparison_morphed)\n",
    "df_constraint_morphed = df_constraint_morphed.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_morphed.to_string(index=False))\n",
    "\n",
    "# BTS Per-Constraint\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION COUNTS - FILTERED BTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraint_comparison_bts = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    baseline_count = baseline_viols_bts['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_viols_bts['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_bts.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_bts = pd.DataFrame(constraint_comparison_bts)\n",
    "df_constraint_bts = df_constraint_bts.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_bts.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# CROSS-DATASET PER-CONSTRAINT COMPARISON - THREE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-DATASET PER-CONSTRAINT COMPARISON - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cross_dataset_all = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    cross_dataset_all.append({\n",
    "        'Constraint': constraint,\n",
    "        'GTSRB Baseline': baseline_viols_gtsrb['constraint_counts'].get(constraint, 0),\n",
    "        'GTSRB Fuzzy': fuzzy_viols_gtsrb['constraint_counts'].get(constraint, 0),\n",
    "        'GTSRB Improvement': baseline_viols_gtsrb['constraint_counts'].get(constraint, 0) - \n",
    "                             fuzzy_viols_gtsrb['constraint_counts'].get(constraint, 0),\n",
    "        'Morphed GTSRB Baseline': baseline_viols_morphed['constraint_counts'].get(constraint, 0),\n",
    "        'Morphed GTSRB Fuzzy': fuzzy_viols_morphed['constraint_counts'].get(constraint, 0),\n",
    "        'Morphed GTSRB Improvement': baseline_viols_morphed['constraint_counts'].get(constraint, 0) - \n",
    "                                     fuzzy_viols_morphed['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Baseline': baseline_viols_bts['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Fuzzy': fuzzy_viols_bts['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Improvement': baseline_viols_bts['constraint_counts'].get(constraint, 0) - \n",
    "                          fuzzy_viols_bts['constraint_counts'].get(constraint, 0)\n",
    "    })\n",
    "\n",
    "df_cross_dataset_all = pd.DataFrame(cross_dataset_all)\n",
    "print(\"\\n\" + df_cross_dataset_all.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# IMPROVEMENT ANALYSIS - ALL DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT ANALYSIS - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gtsrb_improvement = baseline_viols_gtsrb['violation_rate'] - fuzzy_viols_gtsrb['violation_rate']\n",
    "morphed_improvement = baseline_viols_morphed['violation_rate'] - fuzzy_viols_morphed['violation_rate']\n",
    "bts_improvement = baseline_viols_bts['violation_rate'] - fuzzy_viols_bts['violation_rate']\n",
    "\n",
    "print(f\"\\nGTSRB Dataset (In-Distribution):\")\n",
    "print(f\"  Baseline violation rate:  {baseline_viols_gtsrb['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_viols_gtsrb['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {gtsrb_improvement:.2f} percentage points\")\n",
    "if baseline_viols_gtsrb['violation_rate'] > 0:\n",
    "    print(f\"  Relative improvement:     {(gtsrb_improvement / baseline_viols_gtsrb['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nMorphed GTSRB Dataset (Near OOD):\")\n",
    "print(f\"  Baseline violation rate:  {baseline_viols_morphed['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_viols_morphed['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {morphed_improvement:.2f} percentage points\")\n",
    "if baseline_viols_morphed['violation_rate'] > 0:\n",
    "    print(f\"  Relative improvement:     {(morphed_improvement / baseline_viols_morphed['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nFiltered BTS Dataset (Near OOD):\")\n",
    "print(f\"  Baseline violation rate:  {baseline_viols_bts['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_viols_bts['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {bts_improvement:.2f} percentage points\")\n",
    "if baseline_viols_bts['violation_rate'] > 0:\n",
    "    print(f\"  Relative improvement:     {(bts_improvement / baseline_viols_bts['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY - RQ3 ROBUSTNESS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nViolation Rate Reductions Across All Datasets:\")\n",
    "print(f\"  1. GTSRB (In-Dist):       {gtsrb_improvement:.2f} pp\", end=\"\")\n",
    "if baseline_viols_gtsrb['violation_rate'] > 0:\n",
    "    print(f\" ({(gtsrb_improvement / baseline_viols_gtsrb['violation_rate'] * 100):+.2f}%)\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"  2. Morphed GTSRB:         {morphed_improvement:.2f} pp\", end=\"\")\n",
    "if baseline_viols_morphed['violation_rate'] > 0:\n",
    "    print(f\" ({(morphed_improvement / baseline_viols_morphed['violation_rate'] * 100):+.2f}%)\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"  3. BTS:                   {bts_improvement:.2f} pp\", end=\"\")\n",
    "if baseline_viols_bts['violation_rate'] > 0:\n",
    "    print(f\" ({(bts_improvement / baseline_viols_bts['violation_rate'] * 100):+.2f}%)\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RQ3 ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainreq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
