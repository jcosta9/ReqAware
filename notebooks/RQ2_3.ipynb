{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59355f2f",
   "metadata": {},
   "source": [
    "#### RQ3: How does the induction of domain requirements impact the robustness of the Concept Bottleneck Model?\n",
    "The aim of this RQ is to show that the model becomes more robust and logical with respect to images that it has not been trained on. For this purpose we use images from the GTSRB test set that have been morphed, images from the Belgium Traffic Sign dataset that cannot be directly mapped to the GTSRB i.e., unseen traffic signs and images from a far OOD dataset the CIFAR-10 to evaluate what impact the introduction of domain requirements has for images that have none of the characteristics of traffic signs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673addd1",
   "metadata": {},
   "source": [
    "#### Setting up configs and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ee0c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 00:09:37.548428: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-24 00:09:37.564282: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761257377.580882   55053 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761257377.585938   55053 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-24 00:09:37.603407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from models.architectures import CBMSequentialEfficientNetFCN\n",
    "from config import load_config\n",
    "from models.trainer.cbm_trainer import CBMTrainer\n",
    "from rule_eval import construct_full_graph\n",
    "import pandas as pd\n",
    "\n",
    "# Import utility functions\n",
    "from utils.analysis_utils import (\n",
    "    get_dataset_predictions,\n",
    "    analyze_fuzzy_loss_single_model,\n",
    "    compare_fuzzy_losses,\n",
    "    analyze_rule_violations,\n",
    "    compare_violations,\n",
    "    print_fuzzy_loss_results,\n",
    "    print_violation_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99377db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(\"../files/configs/\")\n",
    "models_path = Path(\"../files/models/\")\n",
    "data_path = Path(\"../../../data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9652ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'experiments/20251024_000936_s42' created successfully.\n",
      "Directory 'experiments/20251024_000936_s42' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# model configs and model loading\n",
    "baseline_cbm_config = load_config(config_path / \"GTSRB_CBM_config_loading.yaml\")\n",
    "baseline_cbm = CBMSequentialEfficientNetFCN(baseline_cbm_config)\n",
    "\n",
    "fuzzy_cbm_config = load_config(config_path / \"GTSRB_CBM_config_best_trial_loading.yaml\")\n",
    "fuzzy_cbm = CBMSequentialEfficientNetFCN(fuzzy_cbm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf93eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_label_predictor = models_path / \"20251007_163247_label_predictor_best_model.pt\"\n",
    "baseline_cbm_concept_predictor_path = models_path / \"20251016_224601_s907_baseline_concept_predictor_best_model.pt\"\n",
    "baseline_cbm_label_predictor_path = ground_truth_label_predictor\n",
    "fuzzy_cbm_concept_predictor_path = models_path / \"20251020_223819_s269_concept_predictor_best_model.pt\"\n",
    "fuzzy_cbm_label_precitor_path = ground_truth_label_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045d65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model paths for loading models\n",
    "# baseline_cbm_concept_predictor_path = Path(\"../notebooks/best_acc_models/20251016_224601_s907_baseline_concept_predictor_best_model.pt\")\n",
    "# baseline_cbm_label_predictor_path = Path(\"../experiments/baseline_cbm/models/20251001_083717_label_predictor_best_model.pt\")\n",
    "# fuzzy_cbm_concept_predictor_path = Path(\"../notebooks/best_acc_models/20251020_223819_s269_concept_predictor_best_model.pt\")\n",
    "# fuzzy_cbm_label_precitor_path = Path(\"../experiments/fuzzy_CBM/models/20251001_113637_label_predictor_best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3ded21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Baseline CBM: ../files/models\n",
      "  Fuzzy CBM:    ../files/models\n"
     ]
    }
   ],
   "source": [
    "# Load the baseline model components weights\n",
    "baseline_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_concept_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "baseline_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_label_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Load the fuzzy model components weights\n",
    "fuzzy_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_concept_predictor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "fuzzy_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_label_precitor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Set models to evaluation mode\n",
    "baseline_cbm.eval()\n",
    "fuzzy_cbm.eval()\n",
    "\n",
    "print(f\"  Baseline CBM: {baseline_cbm_concept_predictor_path.parent}\")\n",
    "print(f\"  Fuzzy CBM:    {fuzzy_cbm_concept_predictor_path.parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d851dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "test_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders()\n",
    "train_loader = dataset_factory.train_dataloader\n",
    "val_loader = dataset_factory.val_dataloader\n",
    "test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Trainers and Get Fuzzy Loss Function\n",
    "baseline_cbm_trainer = CBMTrainer(\n",
    "    config=baseline_cbm_config,\n",
    "    model=baseline_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "fuzzy_cbm_trainer = CBMTrainer(\n",
    "    config=fuzzy_cbm_config,\n",
    "    model=fuzzy_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "# Get the fuzzy loss function\n",
    "neutral_fuzzy_loss = fuzzy_cbm_trainer.concept_predictor_trainer.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5200784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- All concepts\n",
      "   - All colors\n",
      "      - Main colors\n",
      "         - Border colors\n",
      "         - Arrow symbols\n",
      "            - All symbols\n",
      "               - General symbols\n",
      "               - Curve symbols\n",
      "               - Warning concepts\n",
      "                  - Warning symbols\n",
      "                  - All shapes\n",
      "               - Regulatory signs\n"
     ]
    }
   ],
   "source": [
    "# Load rule checker\n",
    "rule_checker = construct_full_graph(baseline_cbm_config.dataset.concepts_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127509d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1d97ba",
   "metadata": {},
   "source": [
    "#### Loading the GTSRB test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b87ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "test_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load GTSRB Dataset\n",
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders()\n",
    "\n",
    "test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490520fc",
   "metadata": {},
   "source": [
    "#### Loading the morphed GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc08053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1), scale=(0.9, 1.1), shear=[-5.0, 5.0])\n",
      "    ColorJitter(brightness=(0.85, 1.15), contrast=(0.85, 1.15), saturation=(0.85, 1.15), hue=(-0.05, 0.05))\n",
      "    <data_access.preprocess.contrastEnhancement.ContrastEnhancement object at 0x7fa7a5dbd750>\n",
      "    <data_access.preprocess.retinex.Retinex object at 0x7fa7a5d0b6d0>\n",
      "    <data_access.preprocess.histogramEqual.HistogramEqualization object at 0x7fa7a5079450>\n",
      "    <data_access.preprocess.edgeEnhancement.EdgeEnhancement object at 0x7fa7a50625d0>\n",
      "    ToTensor()\n",
      "    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "test_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1), scale=(0.9, 1.1), shear=[-5.0, 5.0])\n",
      "    ColorJitter(brightness=(0.85, 1.15), contrast=(0.85, 1.15), saturation=(0.85, 1.15), hue=(-0.05, 0.05))\n",
      "    <data_access.preprocess.contrastEnhancement.ContrastEnhancement object at 0x7fa7a5dbd750>\n",
      "    <data_access.preprocess.retinex.Retinex object at 0x7fa7a5d0b6d0>\n",
      "    <data_access.preprocess.histogramEqual.HistogramEqualization object at 0x7fa7a5079450>\n",
      "    <data_access.preprocess.edgeEnhancement.EdgeEnhancement object at 0x7fa7a50625d0>\n",
      "    ToTensor()\n",
      "    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# loading the morphed GTSRB dataset\n",
    "from data_access.datasets.GTSRBFactory import reicnn_transform_TRAIN\n",
    "\n",
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders(train_transform=reicnn_transform_TRAIN, test_transform=reicnn_transform_TRAIN)\n",
    "morphed_gtsrb_test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665126d7",
   "metadata": {},
   "source": [
    "#### Loading the unmapped BTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "843e5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "test_transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# loading the BTS and filtering out the signs that cannot be mapped \n",
    "# fixing seed to ensuring reproducibility\n",
    "from config.dataset_config import ConceptDatasetConfig\n",
    "\n",
    "# Create BTS dataset configuration\n",
    "bts_config = ConceptDatasetConfig(\n",
    "    name=\"bts\",\n",
    "    n_labels=62,  \n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle_dataset=False,\n",
    "    pin_memory=True,\n",
    "    data_path=data_path / \"BTS\",\n",
    "    val_split=0.2\n",
    "\n",
    ")\n",
    "# Resolve the configuration to validate paths and load concept map\n",
    "bts_config.resolve()\n",
    "\n",
    "# Create the dataset factory\n",
    "from data_access.datasets import GTSRBFactory\n",
    "\n",
    "bts_factory = GTSRBFactory(config=bts_config, seed=fuzzy_cbm_config.seed)\n",
    "bts_factory.set_dataloaders()\n",
    "\n",
    "# Access the dataloaders\n",
    "bts_test_loader = bts_factory.test_dataloader\n",
    "bts_train_loader = bts_factory.train_dataloader\n",
    "bts_val_loader = bts_factory.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2f9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of each sign in the GTSRB and how it is mapped to the BTS. If there is an unambiguous mapping, the value is set to the BST label, otherwise it is -1. \n",
    "labels_id_GTS_to_BTS = [-1,-1,-1,-1,-1,-1,-1,-1,-1,31,-1,17,61,19,21,28,25,22,13,3,4,5,0,2,16,10,-1,-1,-1,8,-1,-1,-1,-1,-1,34,-1,-1,35,-1,37,-1,-1]\n",
    "mapping_BTS_to_GTSRB = {i : labels_id_GTS_to_BTS.index(i) for i in labels_id_GTS_to_BTS if i != -1}\n",
    "Belgium_ID_to_Name = {0: \"Bumpy road\",1: \"Bump\",2: \"Slippery road\",3: \"Bend to The left\",4: \"Bend to The right\",5: \"Double curves first to the left\",6: \"Double curves first to the right\",7: \"School zone\",8: \"Bikes can be cross\",9: \"Domestic animal crossing\",10: \"Roadworks\",11: \"Traffic light\",12: \"Gated railroad crossing ahead\",13: \"Caution\",14: \"Road narrows\",15: \"Road narrows on the left\",16: \"Road narrows on the right\",17: \"Intersection with priority\",18: \"Intersection with priority to the right\",19: \"Yield\",20: \"Yield to incoming traffic\",21: \"Stop\",22: \"No entry\",23: \"No entry for cyclists\",24: \"No vehicle over 2t\",25: \"No entry for trucks\",26: \"Width limit\",27: \"Height limit\",28: \"No vehicles\",29: \"No left turn\",30: \"No right turn\",31: \"No overtaking\",32: \"Speed limit\",33: \"Shared path for pedestrians and cyclists\",34: \"Ahead only\",35: \"Right only\",36: \"Ahead and right only\",37: \"Roundabout\",38: \"Cycleway\",39: \"Segregated path for pedestrians and cyclists\",40: \"No parking\",41: \"No stopping\",42: \"No parking from the 1st till 15th day of the month\",43: \"No parking from the 16th till last day of the month\",44: \"Priority over oncoming traffic\",45: \"Parking permitted\",46: \"Parking for disabled\",47: \"Parking reserved for motorcycles, cars, vans (< 3.5t) and minibusses\",48: \"Parking reserved for trucks\",49: \"Parking reserved for coaches\",50: \"Parking mandatory on the verge or sidewalk\",51: \"Start of a living street\",52: \"End of living street\",53: \"One-way road\",54: \"Dead end\",55: \"End of roadworks\",56: \"Pedestrian crossing\",57: \"Cyclist and moped crossing\",58: \"Parking lot\",59: \"Hump\",60: \"End of priority road\",61: \"Priority road\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c164b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering BTS datasets to only include unambiguous mappings to GTSRB...\n",
      "Valid BTS labels: [0, 2, 3, 4, 5, 8, 10, 13, 16, 17, 19, 21, 22, 25, 28, 31, 34, 35, 37, 61]\n",
      "Number of valid labels: 20\n",
      "\n",
      "Original BTS train size: 3660\n",
      "Valid indices found: 2309\n",
      "Filtered BTS train size: 2309\n",
      "\n",
      "Filtered dataloader created successfully!\n",
      "Dataloader ready: bts_train_loader_filtered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Get labels that have unambiguous mapping to GTSRB\n",
    "valid_bts_labels = [i for i in labels_id_GTS_to_BTS if i != -1]\n",
    "\n",
    "# Filter the BTS datasets\n",
    "print(\"Filtering BTS datasets to only include unambiguous mappings to GTSRB...\")\n",
    "print(f\"Valid BTS labels: {sorted(valid_bts_labels)}\")\n",
    "print(f\"Number of valid labels: {len(valid_bts_labels)}\")\n",
    "\n",
    "# Filter train dataset - get valid indices\n",
    "valid_indices = []\n",
    "for idx in range(len(bts_factory.train_dataset)):\n",
    "    try:\n",
    "        _, _, label_data = bts_factory.train_dataset[idx]\n",
    "        # Handle both tuple and single label formats\n",
    "        if isinstance(label_data, tuple):\n",
    "            label = label_data[0].item() if hasattr(label_data[0], 'item') else label_data[0]\n",
    "        else:\n",
    "            label = label_data.item() if hasattr(label_data, 'item') else label_data\n",
    "        \n",
    "        if label not in valid_bts_labels:\n",
    "            valid_indices.append(idx)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not process index {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nOriginal BTS train size: {len(bts_factory.train_dataset)}\")\n",
    "print(f\"Valid indices found: {len(valid_indices)}\")\n",
    "\n",
    "# Create filtered dataset using Subset\n",
    "bts_train_filtered = Subset(bts_factory.train_dataset, valid_indices)\n",
    "print(f\"Filtered BTS train size: {len(bts_train_filtered)}\")\n",
    "\n",
    "# Create dataloader with filtered dataset\n",
    "bts_train_loader_filtered = DataLoader(\n",
    "    bts_train_filtered,\n",
    "    batch_size=bts_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=bts_config.pin_memory,\n",
    ")\n",
    "\n",
    "print(\"\\nFiltered dataloader created successfully!\")\n",
    "print(f\"Dataloader ready: bts_train_loader_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af119166",
   "metadata": {},
   "source": [
    "#### Loading the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc3d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from data_access.datasets.CIFAR10Factory import CIFAR10Factory\n",
    "\n",
    "cifar10_config = ConceptDatasetConfig(\n",
    "    name=\"cifar10\",\n",
    "    n_labels=10, \n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle_dataset=False,\n",
    "    pin_memory=True,\n",
    "    data_path=data_path / \"cifar10\",\n",
    "    val_split=0.2\n",
    ")\n",
    "cifar10_config.resolve()\n",
    "\n",
    "cifar10_factory = CIFAR10Factory(config=cifar10_config, seed=fuzzy_cbm_config.seed)\n",
    "cifar10_factory.set_dataloaders()\n",
    "\n",
    "# Access the dataloaders\n",
    "cifar10_test_loader = cifar10_factory.test_dataloader\n",
    "cifar10_train_loader = cifar10_factory.train_dataloader\n",
    "cifar10_val_loader = cifar10_factory.val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f40111",
   "metadata": {},
   "source": [
    "#### Printing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff41e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RQ2/3: ROBUSTNESS ANALYSIS ON OUT-OF-DISTRIBUTION DATASETS\n",
      "================================================================================\n",
      "\n",
      "Analyzing three datasets:\n",
      "  0. GTSRB (ID - Baseline)\n",
      "  1. Morphed GTSRB (Near OOD - data augmentation)\n",
      "  2. Filtered BTS  (Near OOD - different traffic signs)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE ANALYSIS: MORPHED GTSRB, FILTERED BTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RQ2/3: ROBUSTNESS ANALYSIS ON OUT-OF-DISTRIBUTION DATASETS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAnalyzing three datasets:\")\n",
    "print(\"  0. GTSRB (ID - Baseline)\")\n",
    "print(\"  1. Morphed GTSRB (Near OOD - data augmentation)\")\n",
    "print(\"  2. Filtered BTS  (Near OOD - different traffic signs)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Storage for all results\n",
    "all_predictions = {}\n",
    "all_fuzzy_metrics = {}\n",
    "all_violations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "775fcbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYZING GTSRB DATASET (In-Distribution)\n",
      "================================================================================\n",
      "\n",
      "Getting predictions from both models on GTSRB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting GTSRB (Baseline) predictions: 100%|██████████| 99/99 [00:31<00:00,  3.13it/s]\n",
      "Getting GTSRB (Fuzzy) predictions: 100%|██████████| 99/99 [00:34<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FUZZY LOSS ANALYSIS - GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on GTSRB:\n",
      "  Standard BCE Loss:    0.0001667015\n",
      "  Fuzzy Rules Loss:     1.5138125420\n",
      "  Total Loss:           1.5139792434\n",
      "\n",
      "Fuzzy CBM on GTSRB:\n",
      "  Standard BCE Loss:    0.0001358586\n",
      "  Fuzzy Rules Loss:     1.5131813288\n",
      "  Total Loss:           1.5133171873\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.0006312132\n",
      "    Relative: 0.04%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RULE VIOLATION ANALYSIS - GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 9\n",
      "  Violation rate:          0.07%\n",
      "\n",
      "Fuzzy CBM on GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 14\n",
      "  Violation rate:          0.11%\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: -0.04 percentage points\n",
      "    Relative: -55.56%\n",
      "\n",
      "================================================================================\n",
      "PER-RULE FUZZY LOSS COMPARISON - GTSRB\n",
      "================================================================================\n",
      "\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "     at_most_one_border_colour   1.156952e-05    0.000000e+00  1.156952e-05     100.000000\n",
      "no_symbols_exactly_two_colours   8.708378e-04    3.486726e-04  5.221652e-04      59.961246\n",
      "           at_most_one_warning   1.229602e-02    1.211789e-02  1.781266e-04       1.448653\n",
      "      warning_sign_exclusivity   4.653594e-04    4.614065e-04  3.952911e-06       0.849432\n",
      "             exactly_one_shape   7.501224e-01    7.501248e-01 -2.384186e-06      -0.000318\n",
      "       exactly_one_main_colour   7.500464e-01    7.501285e-01 -8.213520e-05      -0.010951\n",
      "    warning_implies_main_white   2.911803e-09    3.345977e-08 -3.054797e-08   -1049.108593\n",
      "    warning_implies_border_red   3.633854e-10    1.664966e-08 -1.628627e-08   -4481.817932\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 0. GTSRB ANALYSIS (In-Distribution - for comparison baseline)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING GTSRB DATASET (In-Distribution)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from both models\n",
    "print(\"\\nGetting predictions from both models on GTSRB...\")\n",
    "baseline_preds_gtsrb = get_dataset_predictions(\n",
    "    baseline_cbm, test_loader, baseline_cbm_config.device, \"GTSRB (Baseline)\"\n",
    ")\n",
    "fuzzy_preds_gtsrb = get_dataset_predictions(\n",
    "    fuzzy_cbm, test_loader, fuzzy_cbm_config.device, \"GTSRB (Fuzzy)\"\n",
    ")\n",
    "\n",
    "# FUZZY LOSS ANALYSIS - GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_fuzzy_gtsrb = analyze_fuzzy_loss_single_model(\n",
    "    baseline_preds_gtsrb['logits'], \n",
    "    baseline_preds_gtsrb['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Baseline CBM', \n",
    "    'GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_fuzzy_gtsrb = analyze_fuzzy_loss_single_model(\n",
    "    fuzzy_preds_gtsrb['logits'], \n",
    "    fuzzy_preds_gtsrb['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Fuzzy CBM', \n",
    "    'GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_comparison_gtsrb = compare_fuzzy_losses(baseline_fuzzy_gtsrb, fuzzy_fuzzy_gtsrb)\n",
    "\n",
    "print_fuzzy_loss_results(baseline_fuzzy_gtsrb)\n",
    "print_fuzzy_loss_results(fuzzy_fuzzy_gtsrb, fuzzy_comparison_gtsrb)\n",
    "\n",
    "# RULE VIOLATION ANALYSIS - GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_viols_gtsrb = analyze_rule_violations(\n",
    "    baseline_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "fuzzy_viols_gtsrb = analyze_rule_violations(\n",
    "    fuzzy_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "violation_comparison_gtsrb = compare_violations(baseline_viols_gtsrb, fuzzy_viols_gtsrb)\n",
    "\n",
    "print_violation_results(baseline_viols_gtsrb)\n",
    "print_violation_results(fuzzy_viols_gtsrb, violation_comparison_gtsrb)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE FUZZY LOSS COMPARISON - GTSRB\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + fuzzy_comparison_gtsrb['rule_comparison'].to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "all_predictions['gtsrb_baseline'] = baseline_preds_gtsrb\n",
    "all_predictions['gtsrb_fuzzy'] = fuzzy_preds_gtsrb\n",
    "all_fuzzy_metrics['GTSRB_baseline'] = baseline_fuzzy_gtsrb\n",
    "all_fuzzy_metrics['GTSRB_fuzzy'] = fuzzy_fuzzy_gtsrb\n",
    "all_violations['GTSRB_baseline'] = baseline_viols_gtsrb\n",
    "all_violations['GTSRB_fuzzy'] = fuzzy_viols_gtsrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4f2befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYZING MORPHED GTSRB DATASET (Near OOD - Augmented)\n",
      "================================================================================\n",
      "\n",
      "Getting predictions from both models on Morphed GTSRB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Morphed GTSRB (Baseline) predictions: 100%|██████████| 99/99 [27:28<00:00, 16.65s/it]\n",
      "Getting Morphed GTSRB (Fuzzy) predictions: 100%|██████████| 99/99 [27:33<00:00, 16.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FUZZY LOSS ANALYSIS - MORPHED GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Morphed GTSRB:\n",
      "  Standard BCE Loss:    0.0218669530\n",
      "  Fuzzy Rules Loss:     1.6193125248\n",
      "  Total Loss:           1.6411794778\n",
      "\n",
      "Fuzzy CBM on Morphed GTSRB:\n",
      "  Standard BCE Loss:    0.0072932197\n",
      "  Fuzzy Rules Loss:     1.6075688601\n",
      "  Total Loss:           1.6148620797\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.0117436647\n",
      "    Relative: 0.73%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RULE VIOLATION ANALYSIS - MORPHED GTSRB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Morphed GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 1479\n",
      "  Violation rate:          11.71%\n",
      "\n",
      "Fuzzy CBM on Morphed GTSRB:\n",
      "  Total samples:           12630\n",
      "  Samples with violations: 1465\n",
      "  Violation rate:          11.60%\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.11 percentage points\n",
      "    Relative: 0.95%\n",
      "\n",
      "================================================================================\n",
      "PER-RULE FUZZY LOSS COMPARISON - MORPHED GTSRB\n",
      "================================================================================\n",
      "\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss  Improvement  Improvement %\n",
      "     at_most_one_border_colour       0.003186    1.868839e-09     0.003186      99.999941\n",
      "    warning_implies_main_white       0.000019    5.781934e-07     0.000018      96.967428\n",
      "    warning_implies_border_red       0.000008    3.802668e-06     0.000005      54.902297\n",
      "      warning_sign_exclusivity       0.000358    3.110806e-04     0.000047      13.033120\n",
      "       exactly_one_main_colour       0.785858    7.639630e-01     0.021895       2.786126\n",
      "             exactly_one_shape       0.776251    7.689120e-01     0.007339       0.945404\n",
      "           at_most_one_warning       0.004910    4.881355e-03     0.000029       0.591625\n",
      "no_symbols_exactly_two_colours       0.048723    6.949681e-02    -0.020774     -42.637886\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. MORPHED GTSRB ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING MORPHED GTSRB DATASET (Near OOD - Augmented)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from both models\n",
    "print(\"\\nGetting predictions from both models on Morphed GTSRB...\")\n",
    "baseline_preds_morphed = get_dataset_predictions(\n",
    "    baseline_cbm, morphed_gtsrb_test_loader, baseline_cbm_config.device, \"Morphed GTSRB (Baseline)\"\n",
    ")\n",
    "fuzzy_preds_morphed = get_dataset_predictions(\n",
    "    fuzzy_cbm, morphed_gtsrb_test_loader, fuzzy_cbm_config.device, \"Morphed GTSRB (Fuzzy)\"\n",
    ")\n",
    "\n",
    "# FUZZY LOSS ANALYSIS - Morphed GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - MORPHED GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_fuzzy_morphed = analyze_fuzzy_loss_single_model(\n",
    "    baseline_preds_morphed['logits'], \n",
    "    baseline_preds_morphed['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Baseline CBM', \n",
    "    'Morphed GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_fuzzy_morphed = analyze_fuzzy_loss_single_model(\n",
    "    fuzzy_preds_morphed['logits'], \n",
    "    fuzzy_preds_morphed['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Fuzzy CBM', \n",
    "    'Morphed GTSRB'\n",
    ")\n",
    "\n",
    "fuzzy_comparison_morphed = compare_fuzzy_losses(baseline_fuzzy_morphed, fuzzy_fuzzy_morphed)\n",
    "\n",
    "print_fuzzy_loss_results(baseline_fuzzy_morphed)\n",
    "print_fuzzy_loss_results(fuzzy_fuzzy_morphed, fuzzy_comparison_morphed)\n",
    "\n",
    "# RULE VIOLATION ANALYSIS - Morphed GTSRB\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - MORPHED GTSRB\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_viols_morphed = analyze_rule_violations(\n",
    "    baseline_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "fuzzy_viols_morphed = analyze_rule_violations(\n",
    "    fuzzy_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "violation_comparison_morphed = compare_violations(baseline_viols_morphed, fuzzy_viols_morphed)\n",
    "\n",
    "print_violation_results(baseline_viols_morphed)\n",
    "print_violation_results(fuzzy_viols_morphed, violation_comparison_morphed)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE FUZZY LOSS COMPARISON - MORPHED GTSRB\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + fuzzy_comparison_morphed['rule_comparison'].to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "all_predictions['morphed_baseline'] = baseline_preds_morphed\n",
    "all_predictions['morphed_fuzzy'] = fuzzy_preds_morphed\n",
    "all_fuzzy_metrics['Morphed GTSRB_baseline'] = baseline_fuzzy_morphed\n",
    "all_fuzzy_metrics['Morphed GTSRB_fuzzy'] = fuzzy_fuzzy_morphed\n",
    "all_violations['Morphed GTSRB_baseline'] = baseline_viols_morphed\n",
    "all_violations['Morphed GTSRB_fuzzy'] = fuzzy_viols_morphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed51ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYZING FILTERED BTS DATASET (Near OOD - Different Traffic Signs)\n",
      "================================================================================\n",
      "\n",
      "Getting predictions from both models on Filtered BTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Filtered BTS (Baseline) predictions: 100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "Getting Filtered BTS (Fuzzy) predictions: 100%|██████████| 37/37 [00:03<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FUZZY LOSS ANALYSIS - FILTERED BTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Filtered BTS:\n",
      "  Standard BCE Loss:    0.0062498502\n",
      "  Fuzzy Rules Loss:     1.6462961435\n",
      "  Total Loss:           1.6525459937\n",
      "\n",
      "Fuzzy CBM on Filtered BTS:\n",
      "  Standard BCE Loss:    0.0051463828\n",
      "  Fuzzy Rules Loss:     1.6260539293\n",
      "  Total Loss:           1.6312003122\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 0.0202422142\n",
      "    Relative: 1.23%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RULE VIOLATION ANALYSIS - FILTERED BTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline CBM on Filtered BTS:\n",
      "  Total samples:           2309\n",
      "  Samples with violations: 348\n",
      "  Violation rate:          15.07%\n",
      "\n",
      "Fuzzy CBM on Filtered BTS:\n",
      "  Total samples:           2309\n",
      "  Samples with violations: 129\n",
      "  Violation rate:          5.59%\n",
      "\n",
      "  Improvement over Baseline:\n",
      "    Absolute: 9.48 percentage points\n",
      "    Relative: 62.93%\n",
      "\n",
      "================================================================================\n",
      "PER-RULE FUZZY LOSS COMPARISON - FILTERED BTS\n",
      "================================================================================\n",
      "\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "     at_most_one_border_colour   2.334422e-04    0.000000e+00  2.334422e-04     100.000000\n",
      "no_symbols_exactly_two_colours   7.525280e-02    3.645192e-02  3.880088e-02      51.560707\n",
      "    warning_implies_main_white   5.444958e-07    3.310652e-07  2.134306e-07      39.197834\n",
      "             exactly_one_shape   7.550586e-01    7.520954e-01  2.963185e-03       0.392444\n",
      "       exactly_one_main_colour   7.617071e-01    7.608365e-01  8.706450e-04       0.114302\n",
      "      warning_sign_exclusivity   3.140838e-04    3.902604e-04 -7.617660e-05     -24.253593\n",
      "           at_most_one_warning   5.372937e-02    7.627858e-02 -2.254922e-02     -41.968140\n",
      "    warning_implies_border_red   1.866356e-08    9.119072e-07 -8.932436e-07   -4786.030390\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. FILTERED BTS ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING FILTERED BTS DATASET (Near OOD - Different Traffic Signs)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from both models\n",
    "print(\"\\nGetting predictions from both models on Filtered BTS...\")\n",
    "baseline_preds_bts = get_dataset_predictions(\n",
    "    baseline_cbm, bts_train_loader_filtered, baseline_cbm_config.device, \"Filtered BTS (Baseline)\"\n",
    ")\n",
    "fuzzy_preds_bts = get_dataset_predictions(\n",
    "    fuzzy_cbm, bts_train_loader_filtered, fuzzy_cbm_config.device, \"Filtered BTS (Fuzzy)\"\n",
    ")\n",
    "\n",
    "# FUZZY LOSS ANALYSIS - BTS\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - FILTERED BTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_fuzzy_bts = analyze_fuzzy_loss_single_model(\n",
    "    baseline_preds_bts['logits'], \n",
    "    baseline_preds_bts['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Baseline CBM', \n",
    "    'Filtered BTS'\n",
    ")\n",
    "\n",
    "fuzzy_fuzzy_bts = analyze_fuzzy_loss_single_model(\n",
    "    fuzzy_preds_bts['logits'], \n",
    "    fuzzy_preds_bts['predictions'],\n",
    "    neutral_fuzzy_loss, \n",
    "    'Fuzzy CBM', \n",
    "    'Filtered BTS'\n",
    ")\n",
    "\n",
    "fuzzy_comparison_bts = compare_fuzzy_losses(baseline_fuzzy_bts, fuzzy_fuzzy_bts)\n",
    "\n",
    "print_fuzzy_loss_results(baseline_fuzzy_bts)\n",
    "print_fuzzy_loss_results(fuzzy_fuzzy_bts, fuzzy_comparison_bts)\n",
    "\n",
    "# RULE VIOLATION ANALYSIS - BTS\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - FILTERED BTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_viols_bts = analyze_rule_violations(\n",
    "    baseline_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "fuzzy_viols_bts = analyze_rule_violations(\n",
    "    fuzzy_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "violation_comparison_bts = compare_violations(baseline_viols_bts, fuzzy_viols_bts)\n",
    "\n",
    "print_violation_results(baseline_viols_bts)\n",
    "print_violation_results(fuzzy_viols_bts, violation_comparison_bts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE FUZZY LOSS COMPARISON - FILTERED BTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + fuzzy_comparison_bts['rule_comparison'].to_string(index=False))\n",
    "\n",
    "# Store results\n",
    "all_predictions['bts_baseline'] = baseline_preds_bts\n",
    "all_predictions['bts_fuzzy'] = fuzzy_preds_bts\n",
    "all_fuzzy_metrics['Filtered BTS_baseline'] = baseline_fuzzy_bts\n",
    "all_fuzzy_metrics['Filtered BTS_fuzzy'] = fuzzy_fuzzy_bts\n",
    "all_violations['Filtered BTS_baseline'] = baseline_viols_bts\n",
    "all_violations['Filtered BTS_fuzzy'] = fuzzy_viols_bts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d60a9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CROSS-DATASET PER-RULE FUZZY LOSS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "                          Rule  GTSRB Baseline  GTSRB Fuzzy  GTSRB Improvement %  Morphed Baseline  Morphed Fuzzy  Morphed Improvement %  BTS Baseline    BTS Fuzzy  BTS Improvement %\n",
      "     at_most_one_border_colour    1.156952e-05 0.000000e+00           100.000000          0.003186   1.868839e-09              99.999941  2.334422e-04 0.000000e+00         100.000000\n",
      "           at_most_one_warning    1.229602e-02 1.211789e-02             1.448653          0.004910   4.881355e-03               0.591625  5.372937e-02 7.627858e-02         -41.968140\n",
      "       exactly_one_main_colour    7.500464e-01 7.501285e-01            -0.010951          0.785858   7.639630e-01               2.786126  7.617071e-01 7.608365e-01           0.114302\n",
      "             exactly_one_shape    7.501224e-01 7.501248e-01            -0.000318          0.776251   7.689120e-01               0.945404  7.550586e-01 7.520954e-01           0.392444\n",
      "no_symbols_exactly_two_colours    8.708378e-04 3.486726e-04            59.961246          0.048723   6.949681e-02             -42.637886  7.525280e-02 3.645192e-02          51.560707\n",
      "    warning_implies_border_red    3.633854e-10 1.664966e-08         -4481.817932          0.000008   3.802668e-06              54.902297  1.866356e-08 9.119072e-07       -4786.030390\n",
      "    warning_implies_main_white    2.911803e-09 3.345977e-08         -1049.108593          0.000019   5.781934e-07              96.967428  5.444958e-07 3.310652e-07          39.197834\n",
      "      warning_sign_exclusivity    4.653594e-04 4.614065e-04             0.849432          0.000358   3.110806e-04              13.033120  3.140838e-04 3.902604e-04         -24.253593\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CROSS-DATASET PER-RULE FUZZY LOSS COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-DATASET PER-RULE FUZZY LOSS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect all rules across datasets\n",
    "all_rules = set()\n",
    "for comparison in [fuzzy_comparison_gtsrb, fuzzy_comparison_morphed, fuzzy_comparison_bts]:\n",
    "    all_rules.update(comparison['rule_comparison']['Rule'].values)\n",
    "\n",
    "# Build cross-dataset rule comparison\n",
    "cross_dataset_rules = []\n",
    "for rule in sorted(all_rules):\n",
    "    row_data = {'Rule': rule}\n",
    "    \n",
    "    # GTSRB\n",
    "    gtsrb_row = fuzzy_comparison_gtsrb['rule_comparison'][fuzzy_comparison_gtsrb['rule_comparison']['Rule'] == rule]\n",
    "    if not gtsrb_row.empty:\n",
    "        row_data['GTSRB Baseline'] = gtsrb_row.iloc[0]['Baseline Loss']\n",
    "        row_data['GTSRB Fuzzy'] = gtsrb_row.iloc[0]['Fuzzy CBM Loss']\n",
    "        row_data['GTSRB Improvement %'] = gtsrb_row.iloc[0]['Improvement %']\n",
    "    else:\n",
    "        row_data['GTSRB Baseline'] = 0.0\n",
    "        row_data['GTSRB Fuzzy'] = 0.0\n",
    "        row_data['GTSRB Improvement %'] = 0.0\n",
    "    \n",
    "    # Morphed GTSRB\n",
    "    morphed_row = fuzzy_comparison_morphed['rule_comparison'][fuzzy_comparison_morphed['rule_comparison']['Rule'] == rule]\n",
    "    if not morphed_row.empty:\n",
    "        row_data['Morphed Baseline'] = morphed_row.iloc[0]['Baseline Loss']\n",
    "        row_data['Morphed Fuzzy'] = morphed_row.iloc[0]['Fuzzy CBM Loss']\n",
    "        row_data['Morphed Improvement %'] = morphed_row.iloc[0]['Improvement %']\n",
    "    else:\n",
    "        row_data['Morphed Baseline'] = 0.0\n",
    "        row_data['Morphed Fuzzy'] = 0.0\n",
    "        row_data['Morphed Improvement %'] = 0.0\n",
    "    \n",
    "    # BTS\n",
    "    bts_row = fuzzy_comparison_bts['rule_comparison'][fuzzy_comparison_bts['rule_comparison']['Rule'] == rule]\n",
    "    if not bts_row.empty:\n",
    "        row_data['BTS Baseline'] = bts_row.iloc[0]['Baseline Loss']\n",
    "        row_data['BTS Fuzzy'] = bts_row.iloc[0]['Fuzzy CBM Loss']\n",
    "        row_data['BTS Improvement %'] = bts_row.iloc[0]['Improvement %']\n",
    "    else:\n",
    "        row_data['BTS Baseline'] = 0.0\n",
    "        row_data['BTS Fuzzy'] = 0.0\n",
    "        row_data['BTS Improvement %'] = 0.0\n",
    "    \n",
    "    cross_dataset_rules.append(row_data)\n",
    "\n",
    "df_cross_dataset_rules = pd.DataFrame(cross_dataset_rules)\n",
    "print(\"\\n\" + df_cross_dataset_rules.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb170d96",
   "metadata": {},
   "source": [
    "#### Analysing the rule violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "538f874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RULE VIOLATION ANALYSIS - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "Analyzing GTSRB (In-Distribution)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Morphed GTSRB...\n",
      "Analyzing Filtered BTS...\n",
      "\n",
      "================================================================================\n",
      "OVERALL VIOLATION RATE SUMMARY - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "      Dataset     Type        Model  Violation Rate (%)  Violations  Total Samples\n",
      "        GTSRB  In-Dist Baseline CBM            0.071259           9          12630\n",
      "        GTSRB  In-Dist    Fuzzy CBM            0.110847          14          12630\n",
      "Morphed GTSRB Near OOD Baseline CBM           11.710214        1479          12630\n",
      "Morphed GTSRB Near OOD    Fuzzy CBM           11.599367        1465          12630\n",
      " Filtered BTS Near OOD Baseline CBM           15.071460         348           2309\n",
      " Filtered BTS Near OOD    Fuzzy CBM            5.586834         129           2309\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION COUNTS - GTSRB (In-Distribution)\n",
      "================================================================================\n",
      "\n",
      "                        Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      "        Warning symbols constraint               1                0            1     100.000000\n",
      "If arrows present no other symbols               0                0            0       0.000000\n",
      "           Border color constraint               0                0            0       0.000000\n",
      "                Symbols constraint               0                0            0       0.000000\n",
      "       Warning => Main color white               0                0            0       0.000000\n",
      "        General symbols constraint               0                0            0       0.000000\n",
      "   Main and border color different               0                1           -1       0.000000\n",
      "         Warning => Shape Triangle               0                1           -1       0.000000\n",
      "                  Shape constraint               3                4           -1     -33.333333\n",
      "         General concept invariant               7                8           -1     -14.285714\n",
      "            No symbols => 2 colors               6                7           -1     -16.666667\n",
      "       Warning concepts constraint               1                2           -1    -100.000000\n",
      "          General color constraint               1                3           -2    -200.000000\n",
      "             Main color constraint               1                3           -2    -200.000000\n",
      " Main blue => arrow (possible OOD)               0                5           -5       0.000000\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION COUNTS - MORPHED GTSRB\n",
      "================================================================================\n",
      "\n",
      "                        Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      " Main blue => arrow (possible OOD)             386              102          284      73.575130\n",
      "             Main color constraint             606              332          274      45.214521\n",
      "          General color constraint             347              275           72      20.749280\n",
      "       Warning concepts constraint              38                6           32      84.210526\n",
      "           Border color constraint              13                0           13     100.000000\n",
      "        Warning symbols constraint              11                0           11     100.000000\n",
      "                Symbols constraint               7                0            7     100.000000\n",
      "         Warning => Shape Triangle               7                0            7     100.000000\n",
      "If arrows present no other symbols              29               23            6      20.689655\n",
      "       Warning => Main color white               6                1            5      83.333333\n",
      "        General symbols constraint               4                0            4     100.000000\n",
      "            No symbols => 2 colors             756              766          -10      -1.322751\n",
      "   Main and border color different               2               27          -25   -1250.000000\n",
      "                  Shape constraint             523              708         -185     -35.372849\n",
      "         General concept invariant            1175             1366         -191     -16.255319\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION COUNTS - FILTERED BTS\n",
      "================================================================================\n",
      "\n",
      "                        Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      " Main blue => arrow (possible OOD)             298               31          267      89.597315\n",
      "            No symbols => 2 colors             221               71          150      67.873303\n",
      "         General concept invariant             222               82          140      63.063063\n",
      "          General color constraint              35               12           23      65.714286\n",
      "         Warning => Shape Triangle              27               16           11      40.740741\n",
      "             Main color constraint              42               33            9      21.428571\n",
      "                  Shape constraint              13                7            6      46.153846\n",
      "        Warning symbols constraint               1                0            1     100.000000\n",
      "   Main and border color different               0                0            0       0.000000\n",
      "        General symbols constraint               0                0            0       0.000000\n",
      "           Border color constraint               0                0            0       0.000000\n",
      "       Warning => Main color white               0                0            0       0.000000\n",
      "                Symbols constraint               0                0            0       0.000000\n",
      "If arrows present no other symbols               3                4           -1     -33.333333\n",
      "       Warning concepts constraint               1                2           -1    -100.000000\n",
      "\n",
      "================================================================================\n",
      "CROSS-DATASET PER-CONSTRAINT COMPARISON - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "                        Constraint  GTSRB Baseline  GTSRB Fuzzy  GTSRB Improvement  Morphed GTSRB Baseline  Morphed GTSRB Fuzzy  Morphed GTSRB Improvement  BTS Baseline  BTS Fuzzy  BTS Improvement\n",
      "           Border color constraint               0            0                  0                      13                    0                         13             0          0                0\n",
      "          General color constraint               1            3                 -2                     347                  275                         72            35         12               23\n",
      "         General concept invariant               7            8                 -1                    1175                 1366                       -191           222         82              140\n",
      "        General symbols constraint               0            0                  0                       4                    0                          4             0          0                0\n",
      "If arrows present no other symbols               0            0                  0                      29                   23                          6             3          4               -1\n",
      "   Main and border color different               0            1                 -1                       2                   27                        -25             0          0                0\n",
      " Main blue => arrow (possible OOD)               0            5                 -5                     386                  102                        284           298         31              267\n",
      "             Main color constraint               1            3                 -2                     606                  332                        274            42         33                9\n",
      "            No symbols => 2 colors               6            7                 -1                     756                  766                        -10           221         71              150\n",
      "                  Shape constraint               3            4                 -1                     523                  708                       -185            13          7                6\n",
      "                Symbols constraint               0            0                  0                       7                    0                          7             0          0                0\n",
      "       Warning => Main color white               0            0                  0                       6                    1                          5             0          0                0\n",
      "         Warning => Shape Triangle               0            1                 -1                       7                    0                          7            27         16               11\n",
      "       Warning concepts constraint               1            2                 -1                      38                    6                         32             1          2               -1\n",
      "        Warning symbols constraint               1            0                  1                      11                    0                         11             1          0                1\n",
      "\n",
      "================================================================================\n",
      "IMPROVEMENT ANALYSIS - ALL DATASETS\n",
      "================================================================================\n",
      "\n",
      "GTSRB Dataset (In-Distribution):\n",
      "  Baseline violation rate:  0.07%\n",
      "  Fuzzy CBM violation rate: 0.11%\n",
      "  Improvement:              -0.04 percentage points\n",
      "  Relative improvement:     -55.56%\n",
      "\n",
      "Morphed GTSRB Dataset (Near OOD):\n",
      "  Baseline violation rate:  11.71%\n",
      "  Fuzzy CBM violation rate: 11.60%\n",
      "  Improvement:              0.11 percentage points\n",
      "  Relative improvement:     0.95%\n",
      "\n",
      "Filtered BTS Dataset (Near OOD):\n",
      "  Baseline violation rate:  15.07%\n",
      "  Fuzzy CBM violation rate: 5.59%\n",
      "  Improvement:              9.48 percentage points\n",
      "  Relative improvement:     62.93%\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY - RQ3 ROBUSTNESS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Violation Rate Reductions Across All Datasets:\n",
      "  1. GTSRB (In-Dist):       -0.04 pp (-55.56%)\n",
      "  2. Morphed GTSRB:         0.11 pp (+0.95%)\n",
      "  3. BTS:                   9.48 pp (+62.93%)\n",
      "\n",
      "================================================================================\n",
      "RQ3 ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RULE VIOLATION ANALYSIS WITH DETAILED PER-RULE COMPARISON - THREE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze violations for all datasets\n",
    "print(\"\\nAnalyzing GTSRB (In-Distribution)...\")\n",
    "baseline_viols_gtsrb = analyze_rule_violations(\n",
    "    baseline_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "fuzzy_viols_gtsrb = analyze_rule_violations(\n",
    "    fuzzy_preds_gtsrb['predictions'], \n",
    "    'GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "print(\"Analyzing Morphed GTSRB...\")\n",
    "baseline_viols_morphed = analyze_rule_violations(\n",
    "    baseline_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "fuzzy_viols_morphed = analyze_rule_violations(\n",
    "    fuzzy_preds_morphed['predictions'], \n",
    "    'Morphed GTSRB', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "print(\"Analyzing Filtered BTS...\")\n",
    "baseline_viols_bts = analyze_rule_violations(\n",
    "    baseline_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Baseline CBM', \n",
    "    rule_checker\n",
    ")\n",
    "fuzzy_viols_bts = analyze_rule_violations(\n",
    "    fuzzy_preds_bts['predictions'], \n",
    "    'Filtered BTS', \n",
    "    'Fuzzy CBM', \n",
    "    rule_checker\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# OVERALL VIOLATION RATE SUMMARY - THREE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL VIOLATION RATE SUMMARY - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "violation_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Dataset': 'GTSRB',\n",
    "        'Type': 'In-Dist',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_viols_gtsrb['violation_rate'],\n",
    "        'Violations': baseline_viols_gtsrb['total_violations'],\n",
    "        'Total Samples': baseline_viols_gtsrb['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'GTSRB',\n",
    "        'Type': 'In-Dist',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_viols_gtsrb['violation_rate'],\n",
    "        'Violations': fuzzy_viols_gtsrb['total_violations'],\n",
    "        'Total Samples': fuzzy_viols_gtsrb['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Morphed GTSRB',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_viols_morphed['violation_rate'],\n",
    "        'Violations': baseline_viols_morphed['total_violations'],\n",
    "        'Total Samples': baseline_viols_morphed['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Morphed GTSRB',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_viols_morphed['violation_rate'],\n",
    "        'Violations': fuzzy_viols_morphed['total_violations'],\n",
    "        'Total Samples': fuzzy_viols_morphed['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Filtered BTS',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_viols_bts['violation_rate'],\n",
    "        'Violations': baseline_viols_bts['total_violations'],\n",
    "        'Total Samples': baseline_viols_bts['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Filtered BTS',\n",
    "        'Type': 'Near OOD',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_viols_bts['violation_rate'],\n",
    "        'Violations': fuzzy_viols_bts['total_violations'],\n",
    "        'Total Samples': fuzzy_viols_bts['total_samples']\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + violation_summary.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# PER-CONSTRAINT ANALYSIS FOR ALL DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "# Collect all constraints across all datasets\n",
    "all_constraints = (\n",
    "    set(baseline_viols_gtsrb['constraint_counts'].keys()) |\n",
    "    set(baseline_viols_morphed['constraint_counts'].keys()) |\n",
    "    set(baseline_viols_bts['constraint_counts'].keys())\n",
    ")\n",
    "\n",
    "# GTSRB Per-Constraint\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION COUNTS - GTSRB (In-Distribution)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraint_comparison_gtsrb = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    baseline_count = baseline_viols_gtsrb['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_viols_gtsrb['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_gtsrb.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_gtsrb = pd.DataFrame(constraint_comparison_gtsrb)\n",
    "df_constraint_gtsrb = df_constraint_gtsrb.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_gtsrb.to_string(index=False))\n",
    "\n",
    "# Morphed GTSRB Per-Constraint\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION COUNTS - MORPHED GTSRB\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraint_comparison_morphed = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    baseline_count = baseline_viols_morphed['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_viols_morphed['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_morphed.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_morphed = pd.DataFrame(constraint_comparison_morphed)\n",
    "df_constraint_morphed = df_constraint_morphed.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_morphed.to_string(index=False))\n",
    "\n",
    "# BTS Per-Constraint\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION COUNTS - FILTERED BTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraint_comparison_bts = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    baseline_count = baseline_viols_bts['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_viols_bts['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_bts.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_bts = pd.DataFrame(constraint_comparison_bts)\n",
    "df_constraint_bts = df_constraint_bts.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_bts.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# CROSS-DATASET PER-CONSTRAINT COMPARISON - THREE DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-DATASET PER-CONSTRAINT COMPARISON - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cross_dataset_all = []\n",
    "for constraint in sorted(all_constraints):\n",
    "    cross_dataset_all.append({\n",
    "        'Constraint': constraint,\n",
    "        'GTSRB Baseline': baseline_viols_gtsrb['constraint_counts'].get(constraint, 0),\n",
    "        'GTSRB Fuzzy': fuzzy_viols_gtsrb['constraint_counts'].get(constraint, 0),\n",
    "        'GTSRB Improvement': baseline_viols_gtsrb['constraint_counts'].get(constraint, 0) - \n",
    "                             fuzzy_viols_gtsrb['constraint_counts'].get(constraint, 0),\n",
    "        'Morphed GTSRB Baseline': baseline_viols_morphed['constraint_counts'].get(constraint, 0),\n",
    "        'Morphed GTSRB Fuzzy': fuzzy_viols_morphed['constraint_counts'].get(constraint, 0),\n",
    "        'Morphed GTSRB Improvement': baseline_viols_morphed['constraint_counts'].get(constraint, 0) - \n",
    "                                     fuzzy_viols_morphed['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Baseline': baseline_viols_bts['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Fuzzy': fuzzy_viols_bts['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Improvement': baseline_viols_bts['constraint_counts'].get(constraint, 0) - \n",
    "                          fuzzy_viols_bts['constraint_counts'].get(constraint, 0)\n",
    "    })\n",
    "\n",
    "df_cross_dataset_all = pd.DataFrame(cross_dataset_all)\n",
    "print(\"\\n\" + df_cross_dataset_all.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# IMPROVEMENT ANALYSIS - ALL DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT ANALYSIS - ALL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gtsrb_improvement = baseline_viols_gtsrb['violation_rate'] - fuzzy_viols_gtsrb['violation_rate']\n",
    "morphed_improvement = baseline_viols_morphed['violation_rate'] - fuzzy_viols_morphed['violation_rate']\n",
    "bts_improvement = baseline_viols_bts['violation_rate'] - fuzzy_viols_bts['violation_rate']\n",
    "\n",
    "print(f\"\\nGTSRB Dataset (In-Distribution):\")\n",
    "print(f\"  Baseline violation rate:  {baseline_viols_gtsrb['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_viols_gtsrb['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {gtsrb_improvement:.2f} percentage points\")\n",
    "if baseline_viols_gtsrb['violation_rate'] > 0:\n",
    "    print(f\"  Relative improvement:     {(gtsrb_improvement / baseline_viols_gtsrb['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nMorphed GTSRB Dataset (Near OOD):\")\n",
    "print(f\"  Baseline violation rate:  {baseline_viols_morphed['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_viols_morphed['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {morphed_improvement:.2f} percentage points\")\n",
    "if baseline_viols_morphed['violation_rate'] > 0:\n",
    "    print(f\"  Relative improvement:     {(morphed_improvement / baseline_viols_morphed['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nFiltered BTS Dataset (Near OOD):\")\n",
    "print(f\"  Baseline violation rate:  {baseline_viols_bts['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_viols_bts['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {bts_improvement:.2f} percentage points\")\n",
    "if baseline_viols_bts['violation_rate'] > 0:\n",
    "    print(f\"  Relative improvement:     {(bts_improvement / baseline_viols_bts['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY - RQ3 ROBUSTNESS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nViolation Rate Reductions Across All Datasets:\")\n",
    "print(f\"  1. GTSRB (In-Dist):       {gtsrb_improvement:.2f} pp\", end=\"\")\n",
    "if baseline_viols_gtsrb['violation_rate'] > 0:\n",
    "    print(f\" ({(gtsrb_improvement / baseline_viols_gtsrb['violation_rate'] * 100):+.2f}%)\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"  2. Morphed GTSRB:         {morphed_improvement:.2f} pp\", end=\"\")\n",
    "if baseline_viols_morphed['violation_rate'] > 0:\n",
    "    print(f\" ({(morphed_improvement / baseline_viols_morphed['violation_rate'] * 100):+.2f}%)\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"  3. BTS:                   {bts_improvement:.2f} pp\", end=\"\")\n",
    "if baseline_viols_bts['violation_rate'] > 0:\n",
    "    print(f\" ({(bts_improvement / baseline_viols_bts['violation_rate'] * 100):+.2f}%)\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RQ3 ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
