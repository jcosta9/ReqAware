{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec7f2eb",
   "metadata": {},
   "source": [
    "#### RQ1: How does the logical consistency of the CBM change when introducing the requirements via Fuzzy Loss\n",
    "\n",
    "- This RQ aims to evaluate the logical consistency of the CBM and validate the claim that the FuzzyLoss CBM learned the rules and adheres to them.\n",
    "- Load the models\n",
    "- Load the GTSRB Dataset\n",
    "- Load the Raw Fuzzy Loss\n",
    "- Calculate Fuzzy Loss on the test set. (GTSRB, BTS)\n",
    "- Calculate Rule violations on the test set. (GTSRB, BTS)\n",
    "- Calculate the HD on the test set (GTSRB, BTS)\n",
    "- Calculate CL-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82ded96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(f\"{parent_dir}/src\"))\n",
    "\n",
    "from models.architectures import CBMSequentialEfficientNetFCN\n",
    "from train_cbm import cbm_load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fc553ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'experiments/20251009_105749' created successfully.\n",
      "Directory 'experiments/20251009_105749' created successfully.\n"
     ]
    }
   ],
   "source": [
    "baseline_cbm_config = cbm_load_config(Path(\"../files/configs/GTSRB_CBM_config_loading.yaml\"))\n",
    "baseline_cbm = CBMSequentialEfficientNetFCN(baseline_cbm_config)\n",
    "fuzzy_cbm_config = cbm_load_config(Path(\"../files/configs/GTSRB_CBM_config_best_trial_loading.yaml\"))\n",
    "fuzzy_cbm = CBMSequentialEfficientNetFCN(fuzzy_cbm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c18c61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the concrete models\n",
    "baseline_cbm_concept_predictor_path = Path(\"../experiments/20251008_155607/models/20251008_155607_concept_predictor_best_model.pt\")\n",
    "baseline_cbm_label_predictor_path = Path(\"../experiments/baseline_cbm/models/20251001_083717_label_predictor_best_model.pt\")\n",
    "fuzzy_cbm_concept_predictor_path = Path(\"../experiments/20251009_120258/models/20251009_120258_concept_predictor_best_model.pt\")\n",
    "fuzzy_cbm_label_precitor_path = Path(\"../experiments/fuzzy_CBM/models/20251001_113637_label_predictor_best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39d442a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model components loaded successfully!\n",
      "Baseline CBM loaded from ../experiments/20251008_155607/models\n",
      "Fuzzy CBM loaded from ../experiments/20251009_120258/models\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the baseline model components\n",
    "baseline_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_concept_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "baseline_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_label_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Load the fuzzy model components\n",
    "fuzzy_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_concept_predictor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "fuzzy_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_label_precitor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Set models to evaluation mode\n",
    "baseline_cbm.eval()\n",
    "fuzzy_cbm.eval()\n",
    "\n",
    "print(\"Model components loaded successfully!\")\n",
    "print(f\"Baseline CBM loaded from {baseline_cbm_concept_predictor_path.parent}\")\n",
    "print(f\"Fuzzy CBM loaded from {fuzzy_cbm_concept_predictor_path.parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae42f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders()\n",
    "train_loader = dataset_factory.train_dataloader\n",
    "val_loader = dataset_factory.val_dataloader\n",
    "test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba24d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the accuracy on the test of the model\n",
    "from models.trainer.cbm_trainer import CBMTrainer\n",
    "baseline_cbm_trainer = CBMTrainer(\n",
    "    config=baseline_cbm_config,\n",
    "    model=baseline_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "fuzzy_cbm_trainer = CBMTrainer(\n",
    "    config=fuzzy_cbm_config,\n",
    "    model=fuzzy_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee984774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the fuzzy loss function\n",
    "neutral_fuzzy_loss = fuzzy_cbm_trainer.concept_predictor_trainer.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da8fe8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting predictions: 100%|██████████| 99/99 [00:34<00:00,  2.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.5155)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all the predictions on the test set from the fuzzy and the baseline cbm\n",
    "all_logits_fuzzy, concept_predictions_fuzzy, concept_ground_truth_fuzzy, concept_probabilities_fuzzy = fuzzy_cbm_trainer.concept_predictor_trainer.get_predictions(dataloader=test_loader)\n",
    "neutral_fuzzy_loss(torch.tensor(all_logits_fuzzy), torch.tensor(concept_ground_truth_fuzzy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a4a1e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting predictions: 100%|██████████| 99/99 [00:38<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "all_logits_baseline, concept_predictions_baseline, concept_ground_truth_baseline, concept_probabilities_baseline = baseline_cbm_trainer.concept_predictor_trainer.get_predictions(dataloader=test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d9e6885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss metrics for Baseline CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss:   0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss: 100%|██████████| 99/99 [00:47<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing fuzzy loss metrics for Fuzzy CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss: 100%|██████████| 99/99 [00:38<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FUZZY LOSS ANALYSIS - LOGICAL CONSISTENCY METRICS\n",
      "================================================================================\n",
      "\n",
      "Baseline CBM (trained without fuzzy loss):\n",
      "  Standard BCE Loss:    0.0022116409\n",
      "  Fuzzy Rules Loss:     1.5134086369\n",
      "  Total Loss:           1.5156202778\n",
      "\n",
      "  Individual Rule Violations:\n",
      "    at_most_one_border_colour     : 0.0000008134 ( 0.00% of fuzzy loss)\n",
      "    exactly_one_main_colour       : 0.7500880942 (49.56% of fuzzy loss)\n",
      "    exactly_one_shape             : 0.7501135680 (49.56% of fuzzy loss)\n",
      "    between_two_and_three_numbers : 0.0000612766 ( 0.00% of fuzzy loss)\n",
      "    at_most_one_warning           : 0.0121049892 ( 0.80% of fuzzy loss)\n",
      "    no_symbols_exactly_two_colours: 0.0005755201 ( 0.04% of fuzzy loss)\n",
      "    warning_sign_exclusivity      : 0.0004639718 ( 0.03% of fuzzy loss)\n",
      "    warning_implies_main_white    : 0.0000001081 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_border_red    : 0.0000003040 ( 0.00% of fuzzy loss)\n",
      "\n",
      "Fuzzy CBM (trained with fuzzy loss):\n",
      "  Standard BCE Loss:    0.0019492534\n",
      "  Fuzzy Rules Loss:     1.5135019425\n",
      "  Total Loss:           1.5154511959\n",
      "\n",
      "  Individual Rule Violations:\n",
      "    at_most_one_border_colour     : 0.0000001020 ( 0.00% of fuzzy loss)\n",
      "    exactly_one_main_colour       : 0.7501242044 (49.56% of fuzzy loss)\n",
      "    exactly_one_shape             : 0.7501746979 (49.57% of fuzzy loss)\n",
      "    between_two_and_three_numbers : 0.0001335644 ( 0.01% of fuzzy loss)\n",
      "    at_most_one_warning           : 0.0118955279 ( 0.79% of fuzzy loss)\n",
      "    no_symbols_exactly_two_colours: 0.0007183657 ( 0.05% of fuzzy loss)\n",
      "    warning_sign_exclusivity      : 0.0004554813 ( 0.03% of fuzzy loss)\n",
      "    warning_implies_main_white    : 0.0000000008 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_border_red    : 0.0000000019 ( 0.00% of fuzzy loss)\n",
      "\n",
      "================================================================================\n",
      "IMPROVEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Overall Fuzzy Loss Reduction:\n",
      "  Absolute: -0.0000933056\n",
      "  Relative: -0.01%\n",
      "\n",
      "Per-Rule Improvements:\n",
      "  at_most_one_border_colour     : 0.0000007114 (+87.46%)\n",
      "  exactly_one_main_colour       : -0.0000361101 ( -0.00%)\n",
      "  exactly_one_shape             : -0.0000611298 ( -0.01%)\n",
      "  between_two_and_three_numbers : -0.0000722878 (-117.97%)\n",
      "  at_most_one_warning           : 0.0002094613 ( +1.73%)\n",
      "  no_symbols_exactly_two_colours: -0.0001428456 (-24.82%)\n",
      "  warning_sign_exclusivity      : 0.0000084904 ( +1.83%)\n",
      "  warning_implies_main_white    : 0.0000001073 (+99.29%)\n",
      "  warning_implies_border_red    : 0.0000003021 (+99.37%)\n",
      "\n",
      "================================================================================\n",
      "RULE CONTRIBUTION COMPARISON\n",
      "================================================================================\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "    warning_implies_border_red   3.040026e-07    1.901874e-09  3.021007e-07      99.374389\n",
      "    warning_implies_main_white   1.081142e-07    7.692444e-10  1.073450e-07      99.288489\n",
      "     at_most_one_border_colour   8.133698e-07    1.019697e-07  7.114001e-07      87.463301\n",
      "      warning_sign_exclusivity   4.639718e-04    4.554813e-04  8.490410e-06       1.829941\n",
      "           at_most_one_warning   1.210499e-02    1.189553e-02  2.094613e-04       1.730372\n",
      "       exactly_one_main_colour   7.500881e-01    7.501242e-01 -3.611015e-05      -0.004814\n",
      "             exactly_one_shape   7.501136e-01    7.501747e-01 -6.112983e-05      -0.008149\n",
      "no_symbols_exactly_two_colours   5.755201e-04    7.183657e-04 -1.428456e-04     -24.820268\n",
      " between_two_and_three_numbers   6.127656e-05    1.335644e-04 -7.228780e-05    -117.969734\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Number of fuzzy rules evaluated: 9\n",
      "Number of test samples: 12630\n",
      "\n",
      "Logical Consistency Score (lower is better):\n",
      "  Baseline CBM:  1.5134086369\n",
      "  Fuzzy CBM:     1.5135019425\n",
      "  Improvement:   -0.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating the fuzzy neutral fuzzy loss on the test set\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_fuzzy_loss_metrics(model, dataloader, fuzzy_loss_fn, device):\n",
    "    \"\"\"\n",
    "    Compute fuzzy loss metrics for logical consistency evaluation.\n",
    "    \n",
    "    Args:\n",
    "        model: The CBM model to evaluate\n",
    "        dataloader: DataLoader containing the test data\n",
    "        fuzzy_loss_fn: The CustomFuzzyLoss function with fuzzy rules\n",
    "        device: Device to run computations on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing overall and per-rule fuzzy loss metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Accumulators for losses\n",
    "    total_standard_loss = 0.0\n",
    "    total_fuzzy_loss = 0.0\n",
    "    rule_losses = {name: 0.0 for name in fuzzy_loss_fn.fuzzy_rules.keys()}\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (idx, inputs, (concepts, _)) in enumerate(tqdm(dataloader, desc=\"Computing fuzzy loss\")):\n",
    "            inputs = inputs.to(device)\n",
    "            concepts = concepts.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model.concept_predictor(inputs)\n",
    "            \n",
    "            # Compute fuzzy loss (this updates last_standard_loss, last_fuzzy_loss, etc.)\n",
    "            total_loss = fuzzy_loss_fn(outputs, concepts)\n",
    "            \n",
    "            # Accumulate losses\n",
    "            batch_size = inputs.size(0)\n",
    "            num_samples += batch_size\n",
    "            \n",
    "            total_standard_loss += fuzzy_loss_fn.last_standard_loss.item() * batch_size\n",
    "            total_fuzzy_loss += fuzzy_loss_fn.last_fuzzy_loss.item() * batch_size\n",
    "            \n",
    "            # Accumulate individual rule losses\n",
    "            for rule_name, loss_val in fuzzy_loss_fn.last_individual_losses.items():\n",
    "                rule_losses[rule_name] += loss_val.item() * batch_size\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_standard_loss = total_standard_loss / num_samples\n",
    "    avg_fuzzy_loss = total_fuzzy_loss / num_samples\n",
    "    avg_total_loss = avg_standard_loss + avg_fuzzy_loss\n",
    "    avg_rule_losses = {name: loss / num_samples for name, loss in rule_losses.items()}\n",
    "    \n",
    "    # Calculate relative contribution of each rule to total fuzzy loss\n",
    "    rule_contributions = {}\n",
    "    if avg_fuzzy_loss > 0:\n",
    "        rule_contributions = {\n",
    "            name: (loss / num_samples) / avg_fuzzy_loss \n",
    "            for name, loss in rule_losses.items()\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'standard_loss': avg_standard_loss,\n",
    "        'fuzzy_loss': avg_fuzzy_loss,\n",
    "        'total_loss': avg_total_loss,\n",
    "        'rule_losses': avg_rule_losses,\n",
    "        'rule_contributions': rule_contributions,\n",
    "        'num_samples': num_samples\n",
    "    }\n",
    "\n",
    "# Compute fuzzy loss metrics for both models on the test set\n",
    "print(\"Computing fuzzy loss metrics for Baseline CBM...\")\n",
    "baseline_fuzzy_metrics = compute_fuzzy_loss_metrics(\n",
    "    baseline_cbm, \n",
    "    test_loader, \n",
    "    neutral_fuzzy_loss,\n",
    "    baseline_cbm_config.device\n",
    ")\n",
    "\n",
    "print(\"\\nComputing fuzzy loss metrics for Fuzzy CBM...\")\n",
    "fuzzy_cbm_metrics = compute_fuzzy_loss_metrics(\n",
    "    fuzzy_cbm, \n",
    "    test_loader, \n",
    "    neutral_fuzzy_loss,\n",
    "    fuzzy_cbm_config.device\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - LOGICAL CONSISTENCY METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nBaseline CBM (trained without fuzzy loss):\")\n",
    "print(f\"  Standard BCE Loss:    {baseline_fuzzy_metrics['standard_loss']:.10f}\")\n",
    "print(f\"  Fuzzy Rules Loss:     {baseline_fuzzy_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Total Loss:           {baseline_fuzzy_metrics['total_loss']:.10f}\")\n",
    "print(f\"\\n  Individual Rule Violations:\")\n",
    "for rule_name, loss in baseline_fuzzy_metrics['rule_losses'].items():\n",
    "    contribution = baseline_fuzzy_metrics['rule_contributions'].get(rule_name, 0) * 100\n",
    "    print(f\"    {rule_name:30s}: {loss:.10f} ({contribution:5.2f}% of fuzzy loss)\")\n",
    "\n",
    "print(f\"\\nFuzzy CBM (trained with fuzzy loss):\")\n",
    "print(f\"  Standard BCE Loss:    {fuzzy_cbm_metrics['standard_loss']:.10f}\")\n",
    "print(f\"  Fuzzy Rules Loss:     {fuzzy_cbm_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Total Loss:           {fuzzy_cbm_metrics['total_loss']:.10f}\")\n",
    "print(f\"\\n  Individual Rule Violations:\")\n",
    "for rule_name, loss in fuzzy_cbm_metrics['rule_losses'].items():\n",
    "    contribution = fuzzy_cbm_metrics['rule_contributions'].get(rule_name, 0) * 100\n",
    "    print(f\"    {rule_name:30s}: {loss:.10f} ({contribution:5.2f}% of fuzzy loss)\")\n",
    "\n",
    "# Calculate improvements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fuzzy_loss_reduction = baseline_fuzzy_metrics['fuzzy_loss'] - fuzzy_cbm_metrics['fuzzy_loss']\n",
    "fuzzy_loss_reduction_pct = (fuzzy_loss_reduction / baseline_fuzzy_metrics['fuzzy_loss']) * 100\n",
    "\n",
    "print(f\"\\nOverall Fuzzy Loss Reduction:\")\n",
    "print(f\"  Absolute: {fuzzy_loss_reduction:.10f}\")\n",
    "print(f\"  Relative: {fuzzy_loss_reduction_pct:.2f}%\")\n",
    "\n",
    "print(f\"\\nPer-Rule Improvements:\")\n",
    "for rule_name in baseline_fuzzy_metrics['rule_losses'].keys():\n",
    "    baseline_loss = baseline_fuzzy_metrics['rule_losses'][rule_name]\n",
    "    fuzzy_loss = fuzzy_cbm_metrics['rule_losses'][rule_name]\n",
    "    improvement = baseline_loss - fuzzy_loss\n",
    "    improvement_pct = (improvement / baseline_loss) * 100 if baseline_loss > 0 else 0\n",
    "    print(f\"  {rule_name:30s}: {improvement:.10f} ({improvement_pct:+6.2f}%)\")\n",
    "\n",
    "# Visualization of rule contributions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RULE CONTRIBUTION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create comparison dataframe\n",
    "rule_comparison = []\n",
    "for rule_name in baseline_fuzzy_metrics['rule_losses'].keys():\n",
    "    rule_comparison.append({\n",
    "        'Rule': rule_name,\n",
    "        'Baseline Loss': baseline_fuzzy_metrics['rule_losses'][rule_name],\n",
    "        'Fuzzy CBM Loss': fuzzy_cbm_metrics['rule_losses'][rule_name],\n",
    "        'Improvement': baseline_fuzzy_metrics['rule_losses'][rule_name] - fuzzy_cbm_metrics['rule_losses'][rule_name],\n",
    "        'Improvement %': ((baseline_fuzzy_metrics['rule_losses'][rule_name] - fuzzy_cbm_metrics['rule_losses'][rule_name]) \n",
    "                         / baseline_fuzzy_metrics['rule_losses'][rule_name] * 100) if baseline_fuzzy_metrics['rule_losses'][rule_name] > 0 else 0\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(rule_comparison)\n",
    "df_comparison = df_comparison.sort_values('Improvement %', ascending=False)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of fuzzy rules evaluated: {len(baseline_fuzzy_metrics['rule_losses'])}\")\n",
    "print(f\"Number of test samples: {baseline_fuzzy_metrics['num_samples']}\")\n",
    "print(f\"\\nLogical Consistency Score (lower is better):\")\n",
    "print(f\"  Baseline CBM:  {baseline_fuzzy_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Fuzzy CBM:     {fuzzy_cbm_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Improvement:   {fuzzy_loss_reduction_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdd13226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 99/99 [00:58<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fuzzy CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 99/99 [00:36<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Baseline CBM:\n",
      "  Per-prediction accuracy (all concepts correct): 0.9880\n",
      "  Per-concept accuracy (as reported before): 0.9995\n",
      "  Precision: 0.9981\n",
      "  Recall: 0.9970\n",
      "  F1 Score: 0.9975\n",
      "\n",
      "Fuzzy CBM:\n",
      "  Per-prediction accuracy (all concepts correct): 0.9869\n",
      "  Per-concept accuracy (as reported before): 0.9995\n",
      "  Precision: 0.9985\n",
      "  Recall: 0.9968\n",
      "  F1 Score: 0.9977\n",
      "\n",
      "Improvement with Fuzzy Loss:\n",
      "  Per-prediction accuracy: -0.0010 (-0.10%)\n",
      "  Per-concept accuracy: 0.0000 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_prediction_level_accuracy(model, dataloader, device):\n",
    "    \"\"\"Evaluate model accuracy at the prediction level (all concepts must be correct)\"\"\"\n",
    "    model.eval()\n",
    "    all_correct_predictions = 0\n",
    "    all_predictions = 0 \n",
    "    \n",
    "    # For collecting per-concept metrics\n",
    "    concept_true = []\n",
    "    concept_pred = []\n",
    "    \n",
    "    # For collecting per-sample metrics (all concepts must match)\n",
    "    sample_correct = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (idx, inputs, (concepts, _)) in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
    "            inputs = inputs.to(device)\n",
    "            concepts = concepts.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model.concept_predictor(inputs)\n",
    "            \n",
    "            # Get binary predictions\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            # Add to concept-level metrics collection\n",
    "            concept_true.append(concepts.cpu().numpy())\n",
    "            concept_pred.append(preds.cpu().numpy())\n",
    "            \n",
    "            # Calculate prediction-level accuracy (all concepts must be correct)\n",
    "            batch_size = concepts.size(0)\n",
    "            for i in range(batch_size):\n",
    "                # Check if all concepts match for this sample\n",
    "                sample_match = torch.all(preds[i] == concepts[i]).item()\n",
    "                sample_correct.append(sample_match)\n",
    "                \n",
    "            # Update counters\n",
    "            all_predictions += batch_size\n",
    "            all_correct_predictions += torch.sum(torch.all(preds == concepts, dim=1)).item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    prediction_accuracy = all_correct_predictions / all_predictions\n",
    "    \n",
    "    # Calculate per-concept metrics\n",
    "    concept_true = np.vstack(concept_true)\n",
    "    concept_pred = np.vstack(concept_pred)\n",
    "    \n",
    "    # Per-concept accuracy (as currently reported)\n",
    "    concept_accuracy = np.mean((concept_true == concept_pred).flatten())\n",
    "    \n",
    "    # Per-concept precision, recall, F1\n",
    "    precision = precision_score(concept_true.flatten(), concept_pred.flatten(), zero_division=0)\n",
    "    recall = recall_score(concept_true.flatten(), concept_pred.flatten(), zero_division=0)\n",
    "    f1 = f1_score(concept_true.flatten(), concept_pred.flatten(), zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'prediction_accuracy': prediction_accuracy,\n",
    "        'concept_accuracy': concept_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'sample_correct': sample_correct\n",
    "    }\n",
    "\n",
    "# Run evaluation for both models\n",
    "print(\"Evaluating baseline CBM...\")\n",
    "baseline_results = evaluate_prediction_level_accuracy(baseline_cbm, test_loader, baseline_cbm_config.device)\n",
    "\n",
    "print(\"Evaluating fuzzy CBM...\")\n",
    "fuzzy_results = evaluate_prediction_level_accuracy(fuzzy_cbm, test_loader, fuzzy_cbm_config.device)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(f\"Baseline CBM:\")\n",
    "print(f\"  Per-prediction accuracy (all concepts correct): {baseline_results['prediction_accuracy']:.4f}\")\n",
    "print(f\"  Per-concept accuracy (as reported before): {baseline_results['concept_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {baseline_results['precision']:.4f}\")\n",
    "print(f\"  Recall: {baseline_results['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {baseline_results['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nFuzzy CBM:\")\n",
    "print(f\"  Per-prediction accuracy (all concepts correct): {fuzzy_results['prediction_accuracy']:.4f}\")\n",
    "print(f\"  Per-concept accuracy (as reported before): {fuzzy_results['concept_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {fuzzy_results['precision']:.4f}\")\n",
    "print(f\"  Recall: {fuzzy_results['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {fuzzy_results['f1']:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "prediction_improvement = fuzzy_results['prediction_accuracy'] - baseline_results['prediction_accuracy']\n",
    "concept_improvement = fuzzy_results['concept_accuracy'] - baseline_results['concept_accuracy']\n",
    "\n",
    "print(f\"\\nImprovement with Fuzzy Loss:\")\n",
    "print(f\"  Per-prediction accuracy: {prediction_improvement:.4f} ({prediction_improvement*100:.2f}%)\")\n",
    "print(f\"  Per-concept accuracy: {concept_improvement:.4f} ({concept_improvement*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b147b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- All concepts\n",
      "   - All colors\n",
      "      - Main colors\n",
      "         - Border colors\n",
      "         - Arrow symbols\n",
      "   - All shapes\n",
      "   - All symbols\n",
      "      - Number symbols\n",
      "      - General symbols\n",
      "      - Curve symbols\n",
      "      - Warning concepts\n",
      "         - Warning symbols\n",
      "      - Regulatory signs\n"
     ]
    }
   ],
   "source": [
    "# loading the predefined rule checker that constructs a graph of the concept groups and assigns rules on top of them\n",
    "from rule_eval import construct_full_graph\n",
    "rule_checker = construct_full_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc7cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_round']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_round', 'number_0']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_round']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_round']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: Symbols constraint\n",
      "Violating concept names: ['number_0', 'number_8', 'symbol_car', 'symbol_diagonal_stripes']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_square']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_square']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_square']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_triangular']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_white', 'shape_round']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Number of flagged indices in semantic graph: 23\n"
     ]
    }
   ],
   "source": [
    "# evaluating the rules violations on the test set of the fuzzy CBM\n",
    "counter_graph_semantic_relation_fuzzy = 0\n",
    "flagged_indices_graph_semantic_relation_fuzzy = []\n",
    "constraints_violated_relation_fuzzy = []\n",
    "for i, pred in enumerate(concept_predictions_fuzzy):\n",
    "    violated = rule_checker.check_concept_vector(pred, verbose=True, early_stop=True)\n",
    "    if violated:\n",
    "        counter_graph_semantic_relation_fuzzy+= 1\n",
    "        flagged_indices_graph_semantic_relation_fuzzy.append(i)#\n",
    "        constraints_violated_relation_fuzzy.append(violated)\n",
    "\n",
    "# Sanity check for semantic graph\n",
    "print(f\"Number of flagged indices in semantic graph: {len(flagged_indices_graph_semantic_relation_fuzzy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6a81539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_construction_site']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_square']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_triangular']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_triangular']\n",
      "Constraint violated: Main color constraint\n",
      "Violating concept names: ['main_color_white', 'main_color_blue']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_triangular']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: One number\n",
      "Violating concept names: ['number_0']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_attention', 'symbol_traffic_lights']\n",
      "Number of flagged indices in semantic graph: 18\n"
     ]
    }
   ],
   "source": [
    "# evaluating the rule violations on the test set of the baseline CBM\n",
    "counter_graph_semantic_relation_baseline = 0\n",
    "flagged_indices_graph_semantic_relation_baseline = []\n",
    "constraints_violated_relation_baseline = []\n",
    "for i, pred in enumerate(concept_predictions_baseline):\n",
    "    violated = rule_checker.check_concept_vector(pred, verbose=True, early_stop=True)\n",
    "    if violated:\n",
    "        counter_graph_semantic_relation_fuzzy+= 1\n",
    "        flagged_indices_graph_semantic_relation_baseline.append(i)\n",
    "        constraints_violated_relation_baseline.append(violated)\n",
    "\n",
    "# Sanity check for semantic graph\n",
    "print(f\"Number of flagged indices in semantic graph: {len(flagged_indices_graph_semantic_relation_baseline)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
