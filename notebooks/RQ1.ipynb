{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec7f2eb",
   "metadata": {},
   "source": [
    "#### RQ1: How does the logical consistency of the CBM change when introducing the requirements via Fuzzy Loss\n",
    "\n",
    "- This RQ aims to evaluate the logical consistency of the CBM and validate the claim that the FuzzyLoss CBM learned the rules and adheres to them.\n",
    "- Load the models\n",
    "- Load the GTSRB Dataset\n",
    "- Load the Raw Fuzzy Loss\n",
    "- Calculate Fuzzy Loss on the test set. (GTSRB, BTS)\n",
    "- Calculate Rule violations on the test set. (GTSRB, BTS)\n",
    "- Calculate the HD on the test set (GTSRB, BTS)\n",
    "- Calculate CL-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ded96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home-vol2/se/reichmei/.conda/envs/MasterThesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(f\"{parent_dir}/src\"))\n",
    "\n",
    "from models.architectures import CBMSequentialEfficientNetFCN\n",
    "from train_cbm import cbm_load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc553ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'experiments/20251010_150436' created successfully.\n",
      "Directory 'experiments/20251010_150436' created successfully.\n"
     ]
    }
   ],
   "source": [
    "baseline_cbm_config = cbm_load_config(Path(\"../files/configs/GTSRB_CBM_config_loading.yaml\"))\n",
    "baseline_cbm = CBMSequentialEfficientNetFCN(baseline_cbm_config)\n",
    "fuzzy_cbm_config = cbm_load_config(Path(\"../files/configs/GTSRB_CBM_config_best_trial_loading.yaml\"))\n",
    "fuzzy_cbm = CBMSequentialEfficientNetFCN(fuzzy_cbm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18c61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the concrete models\n",
    "baseline_cbm_concept_predictor_path = Path(\"../experiments/20251008_155607/models/20251008_155607_concept_predictor_best_model.pt\")\n",
    "baseline_cbm_label_predictor_path = Path(\"../experiments/baseline_cbm/models/20251001_083717_label_predictor_best_model.pt\")\n",
    "fuzzy_cbm_concept_predictor_path = Path(\"../experiments/20251010_102822/models/20251010_102822_concept_predictor_best_model.pt\")\n",
    "fuzzy_cbm_label_precitor_path = Path(\"../experiments/fuzzy_CBM/models/20251001_113637_label_predictor_best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d442a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model components loaded successfully!\n",
      "Baseline CBM loaded from ../experiments/20251008_155607/models\n",
      "Fuzzy CBM loaded from ../experiments/20251010_102822/models\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the baseline model components\n",
    "baseline_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_concept_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "baseline_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(baseline_cbm_label_predictor_path, map_location=baseline_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Load the fuzzy model components\n",
    "fuzzy_cbm.concept_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_concept_predictor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "fuzzy_cbm.label_predictor.load_state_dict(\n",
    "    torch.load(fuzzy_cbm_label_precitor_path, map_location=fuzzy_cbm_config.device, weights_only=True)\n",
    ")\n",
    "\n",
    "# Set models to evaluation mode\n",
    "baseline_cbm.eval()\n",
    "fuzzy_cbm.eval()\n",
    "\n",
    "print(\"Model components loaded successfully!\")\n",
    "print(f\"Baseline CBM loaded from {baseline_cbm_concept_predictor_path.parent}\")\n",
    "print(f\"Fuzzy CBM loaded from {fuzzy_cbm_concept_predictor_path.parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae42f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_factory = baseline_cbm_config.dataset.factory(\n",
    "    seed=baseline_cbm_config.seed, config=baseline_cbm_config.dataset\n",
    ").set_dataloaders()\n",
    "train_loader = dataset_factory.train_dataloader\n",
    "val_loader = dataset_factory.val_dataloader\n",
    "test_loader = dataset_factory.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba24d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the accuracy on the test of the model\n",
    "from models.trainer.cbm_trainer import CBMTrainer\n",
    "baseline_cbm_trainer = CBMTrainer(\n",
    "    config=baseline_cbm_config,\n",
    "    model=baseline_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "fuzzy_cbm_trainer = CBMTrainer(\n",
    "    config=fuzzy_cbm_config,\n",
    "    model=fuzzy_cbm,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee984774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the fuzzy loss function\n",
    "neutral_fuzzy_loss = fuzzy_cbm_trainer.concept_predictor_trainer.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da8fe8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting predictions: 100%|██████████| 99/99 [01:54<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.5155)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all the predictions on the test set from the fuzzy and the baseline cbm\n",
    "all_logits_fuzzy, concept_predictions_fuzzy, concept_ground_truth_fuzzy, concept_probabilities_fuzzy = fuzzy_cbm_trainer.concept_predictor_trainer.get_predictions(dataloader=test_loader)\n",
    "neutral_fuzzy_loss(torch.tensor(all_logits_fuzzy), torch.tensor(concept_ground_truth_fuzzy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4a1e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting predictions: 100%|██████████| 99/99 [02:47<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "all_logits_baseline, concept_predictions_baseline, concept_ground_truth_baseline, concept_probabilities_baseline = baseline_cbm_trainer.concept_predictor_trainer.get_predictions(dataloader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9e6885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss metrics for Baseline CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss: 100%|██████████| 99/99 [02:49<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing fuzzy loss metrics for Fuzzy CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing fuzzy loss: 100%|██████████| 99/99 [01:19<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FUZZY LOSS ANALYSIS - LOGICAL CONSISTENCY METRICS\n",
      "================================================================================\n",
      "\n",
      "Baseline CBM (trained without fuzzy loss):\n",
      "  Standard BCE Loss:    0.0022116409\n",
      "  Fuzzy Rules Loss:     1.5133473602\n",
      "  Total Loss:           1.5155590011\n",
      "\n",
      "  Individual Rule Violations:\n",
      "    at_most_one_border_colour     : 0.0000008134 ( 0.00% of fuzzy loss)\n",
      "    exactly_one_main_colour       : 0.7500880942 (49.56% of fuzzy loss)\n",
      "    exactly_one_shape             : 0.7501135680 (49.57% of fuzzy loss)\n",
      "    at_most_one_warning           : 0.0121049892 ( 0.80% of fuzzy loss)\n",
      "    no_symbols_exactly_two_colours: 0.0005755201 ( 0.04% of fuzzy loss)\n",
      "    warning_sign_exclusivity      : 0.0004639718 ( 0.03% of fuzzy loss)\n",
      "    warning_implies_main_white    : 0.0000001081 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_border_red    : 0.0000003040 ( 0.00% of fuzzy loss)\n",
      "\n",
      "Fuzzy CBM (trained with fuzzy loss):\n",
      "  Standard BCE Loss:    0.0024025973\n",
      "  Fuzzy Rules Loss:     1.5130741719\n",
      "  Total Loss:           1.5154767692\n",
      "\n",
      "  Individual Rule Violations:\n",
      "    at_most_one_border_colour     : 0.0000016019 ( 0.00% of fuzzy loss)\n",
      "    exactly_one_main_colour       : 0.7500558726 (49.57% of fuzzy loss)\n",
      "    exactly_one_shape             : 0.7500491422 (49.57% of fuzzy loss)\n",
      "    at_most_one_warning           : 0.0118764891 ( 0.78% of fuzzy loss)\n",
      "    no_symbols_exactly_two_colours: 0.0006275345 ( 0.04% of fuzzy loss)\n",
      "    warning_sign_exclusivity      : 0.0004635207 ( 0.03% of fuzzy loss)\n",
      "    warning_implies_main_white    : 0.0000000003 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_border_red    : 0.0000000129 ( 0.00% of fuzzy loss)\n",
      "\n",
      "================================================================================\n",
      "IMPROVEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Overall Fuzzy Loss Reduction:\n",
      "  Absolute: 0.0002731883\n",
      "  Relative: 0.02%\n",
      "\n",
      "Per-Rule Improvements:\n",
      "  at_most_one_border_colour     : -0.0000007885 (-96.95%)\n",
      "  exactly_one_main_colour       : 0.0000322216 ( +0.00%)\n",
      "  exactly_one_shape             : 0.0000644258 ( +0.01%)\n",
      "  at_most_one_warning           : 0.0002285000 ( +1.89%)\n",
      "  no_symbols_exactly_two_colours: -0.0000520144 ( -9.04%)\n",
      "  warning_sign_exclusivity      : 0.0000004511 ( +0.10%)\n",
      "  warning_implies_main_white    : 0.0000001078 (+99.74%)\n",
      "  warning_implies_border_red    : 0.0000002911 (+95.74%)\n",
      "\n",
      "================================================================================\n",
      "RULE CONTRIBUTION COMPARISON\n",
      "================================================================================\n",
      "                          Rule  Baseline Loss  Fuzzy CBM Loss   Improvement  Improvement %\n",
      "    warning_implies_main_white   1.081142e-07    2.784382e-10  1.078358e-07      99.742459\n",
      "    warning_implies_border_red   3.040026e-07    1.294973e-08  2.910528e-07      95.740255\n",
      "           at_most_one_warning   1.210499e-02    1.187649e-02  2.285000e-04       1.887652\n",
      "      warning_sign_exclusivity   4.639718e-04    4.635207e-04  4.510726e-07       0.097220\n",
      "             exactly_one_shape   7.501136e-01    7.500491e-01  6.442583e-05       0.008589\n",
      "       exactly_one_main_colour   7.500881e-01    7.500559e-01  3.222160e-05       0.004296\n",
      "no_symbols_exactly_two_colours   5.755201e-04    6.275345e-04 -5.201440e-05      -9.037807\n",
      "     at_most_one_border_colour   8.133698e-07    1.601907e-06 -7.885369e-07     -96.946910\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Number of fuzzy rules evaluated: 8\n",
      "Number of test samples: 12630\n",
      "\n",
      "Logical Consistency Score (lower is better):\n",
      "  Baseline CBM:  1.5133473602\n",
      "  Fuzzy CBM:     1.5130741719\n",
      "  Improvement:   0.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating the fuzzy neutral fuzzy loss on the test set\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_fuzzy_loss_metrics(model, dataloader, fuzzy_loss_fn, device, normal=False):\n",
    "    \"\"\"\n",
    "    Compute fuzzy loss metrics for logical consistency evaluation.\n",
    "    \n",
    "    Args:\n",
    "        model: The CBM model to evaluate\n",
    "        dataloader: DataLoader containing the test data\n",
    "        fuzzy_loss_fn: The CustomFuzzyLoss function with fuzzy rules\n",
    "        device: Device to run computations on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing overall and per-rule fuzzy loss metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Accumulators for losses\n",
    "    total_standard_loss = 0.0\n",
    "    total_fuzzy_loss = 0.0\n",
    "    rule_losses = {name: 0.0 for name in fuzzy_loss_fn.fuzzy_rules.keys()}\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (idx, inputs, (concepts, _)) in enumerate(tqdm(dataloader, desc=\"Computing fuzzy loss\")):\n",
    "            inputs = inputs.to(device)\n",
    "            concepts = concepts.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model.concept_predictor(inputs)\n",
    "            \n",
    "            # Compute fuzzy loss (this updates last_standard_loss, last_fuzzy_loss, etc.)\n",
    "            total_loss = fuzzy_loss_fn(outputs, concepts)\n",
    "            \n",
    "            # Accumulate losses\n",
    "            batch_size = inputs.size(0)\n",
    "            num_samples += batch_size\n",
    "            \n",
    "            total_standard_loss += fuzzy_loss_fn.last_standard_loss.item() * batch_size\n",
    "            total_fuzzy_loss += fuzzy_loss_fn.last_fuzzy_loss.item() * batch_size\n",
    "            \n",
    "            # Accumulate individual rule losses\n",
    "            for rule_name, loss_val in fuzzy_loss_fn.last_individual_losses.items():\n",
    "                rule_losses[rule_name] += loss_val.item() * batch_size\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_standard_loss = total_standard_loss / num_samples\n",
    "    avg_fuzzy_loss = total_fuzzy_loss / num_samples\n",
    "    avg_total_loss = avg_standard_loss + avg_fuzzy_loss\n",
    "    avg_rule_losses = {name: loss / num_samples for name, loss in rule_losses.items()}\n",
    "    \n",
    "    # Calculate relative contribution of each rule to total fuzzy loss\n",
    "    rule_contributions = {}\n",
    "    if avg_fuzzy_loss > 0:\n",
    "        rule_contributions = {\n",
    "            name: (loss / num_samples) / avg_fuzzy_loss \n",
    "            for name, loss in rule_losses.items()\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'standard_loss': avg_standard_loss,\n",
    "        'fuzzy_loss': avg_fuzzy_loss,\n",
    "        'total_loss': avg_total_loss,\n",
    "        'rule_losses': avg_rule_losses,\n",
    "        'rule_contributions': rule_contributions,\n",
    "        'num_samples': num_samples\n",
    "    }\n",
    "\n",
    "# Compute fuzzy loss metrics for both models on the test set\n",
    "print(\"Computing fuzzy loss metrics for Baseline CBM...\")\n",
    "baseline_fuzzy_metrics = compute_fuzzy_loss_metrics(\n",
    "    baseline_cbm, \n",
    "    test_loader, \n",
    "    neutral_fuzzy_loss,\n",
    "    baseline_cbm_config.device\n",
    ")\n",
    "\n",
    "print(\"\\nComputing fuzzy loss metrics for Fuzzy CBM...\")\n",
    "fuzzy_cbm_metrics = compute_fuzzy_loss_metrics(\n",
    "    fuzzy_cbm, \n",
    "    test_loader, \n",
    "    neutral_fuzzy_loss,\n",
    "    fuzzy_cbm_config.device\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS - LOGICAL CONSISTENCY METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nBaseline CBM (trained without fuzzy loss):\")\n",
    "print(f\"  Standard BCE Loss:    {baseline_fuzzy_metrics['standard_loss']:.10f}\")\n",
    "print(f\"  Fuzzy Rules Loss:     {baseline_fuzzy_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Total Loss:           {baseline_fuzzy_metrics['total_loss']:.10f}\")\n",
    "print(f\"\\n  Individual Rule Violations:\")\n",
    "for rule_name, loss in baseline_fuzzy_metrics['rule_losses'].items():\n",
    "    contribution = baseline_fuzzy_metrics['rule_contributions'].get(rule_name, 0) * 100\n",
    "    print(f\"    {rule_name:30s}: {loss:.10f} ({contribution:5.2f}% of fuzzy loss)\")\n",
    "\n",
    "print(f\"\\nFuzzy CBM (trained with fuzzy loss):\")\n",
    "print(f\"  Standard BCE Loss:    {fuzzy_cbm_metrics['standard_loss']:.10f}\")\n",
    "print(f\"  Fuzzy Rules Loss:     {fuzzy_cbm_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Total Loss:           {fuzzy_cbm_metrics['total_loss']:.10f}\")\n",
    "print(f\"\\n  Individual Rule Violations:\")\n",
    "for rule_name, loss in fuzzy_cbm_metrics['rule_losses'].items():\n",
    "    contribution = fuzzy_cbm_metrics['rule_contributions'].get(rule_name, 0) * 100\n",
    "    print(f\"    {rule_name:30s}: {loss:.10f} ({contribution:5.2f}% of fuzzy loss)\")\n",
    "\n",
    "# Calculate improvements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fuzzy_loss_reduction = baseline_fuzzy_metrics['fuzzy_loss'] - fuzzy_cbm_metrics['fuzzy_loss']\n",
    "fuzzy_loss_reduction_pct = (fuzzy_loss_reduction / baseline_fuzzy_metrics['fuzzy_loss']) * 100\n",
    "\n",
    "print(f\"\\nOverall Fuzzy Loss Reduction:\")\n",
    "print(f\"  Absolute: {fuzzy_loss_reduction:.10f}\")\n",
    "print(f\"  Relative: {fuzzy_loss_reduction_pct:.2f}%\")\n",
    "\n",
    "print(f\"\\nPer-Rule Improvements:\")\n",
    "for rule_name in baseline_fuzzy_metrics['rule_losses'].keys():\n",
    "    baseline_loss = baseline_fuzzy_metrics['rule_losses'][rule_name]\n",
    "    fuzzy_loss = fuzzy_cbm_metrics['rule_losses'][rule_name]\n",
    "    improvement = baseline_loss - fuzzy_loss\n",
    "    improvement_pct = (improvement / baseline_loss) * 100 if baseline_loss > 0 else 0\n",
    "    print(f\"  {rule_name:30s}: {improvement:.10f} ({improvement_pct:+6.2f}%)\")\n",
    "\n",
    "# Visualization of rule contributions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RULE CONTRIBUTION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create comparison dataframe\n",
    "rule_comparison = []\n",
    "for rule_name in baseline_fuzzy_metrics['rule_losses'].keys():\n",
    "    rule_comparison.append({\n",
    "        'Rule': rule_name,\n",
    "        'Baseline Loss': baseline_fuzzy_metrics['rule_losses'][rule_name],\n",
    "        'Fuzzy CBM Loss': fuzzy_cbm_metrics['rule_losses'][rule_name],\n",
    "        'Improvement': baseline_fuzzy_metrics['rule_losses'][rule_name] - fuzzy_cbm_metrics['rule_losses'][rule_name],\n",
    "        'Improvement %': ((baseline_fuzzy_metrics['rule_losses'][rule_name] - fuzzy_cbm_metrics['rule_losses'][rule_name]) \n",
    "                         / baseline_fuzzy_metrics['rule_losses'][rule_name] * 100) if baseline_fuzzy_metrics['rule_losses'][rule_name] > 0 else 0\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(rule_comparison)\n",
    "df_comparison = df_comparison.sort_values('Improvement %', ascending=False)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of fuzzy rules evaluated: {len(baseline_fuzzy_metrics['rule_losses'])}\")\n",
    "print(f\"Number of test samples: {baseline_fuzzy_metrics['num_samples']}\")\n",
    "print(f\"\\nLogical Consistency Score (lower is better):\")\n",
    "print(f\"  Baseline CBM:  {baseline_fuzzy_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Fuzzy CBM:     {fuzzy_cbm_metrics['fuzzy_loss']:.10f}\")\n",
    "print(f\"  Improvement:   {fuzzy_loss_reduction_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd13226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 99/99 [02:17<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fuzzy CBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 99/99 [02:42<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS =====\n",
      "Baseline CBM:\n",
      "  Per-prediction accuracy (all concepts correct): 0.9880\n",
      "  Per-concept accuracy (as reported before): 0.9995\n",
      "  Precision: 0.9981\n",
      "  Recall: 0.9970\n",
      "  F1 Score: 0.9975\n",
      "\n",
      "Fuzzy CBM:\n",
      "  Per-prediction accuracy (all concepts correct): 0.9904\n",
      "  Per-concept accuracy (as reported before): 0.9996\n",
      "  Precision: 0.9985\n",
      "  Recall: 0.9974\n",
      "  F1 Score: 0.9980\n",
      "\n",
      "Improvement with Fuzzy Loss:\n",
      "  Per-prediction accuracy: 0.0025 (0.25%)\n",
      "  Per-concept accuracy: 0.0001 (0.01%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_prediction_level_accuracy(model, dataloader, device):\n",
    "    \"\"\"Evaluate model accuracy at the prediction level (all concepts must be correct)\"\"\"\n",
    "    model.eval()\n",
    "    all_correct_predictions = 0\n",
    "    all_predictions = 0 \n",
    "    \n",
    "    # For collecting per-concept metrics\n",
    "    concept_true = []\n",
    "    concept_pred = []\n",
    "    \n",
    "    # For collecting per-sample metrics (all concepts must match)\n",
    "    sample_correct = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (idx, inputs, (concepts, _)) in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
    "            inputs = inputs.to(device)\n",
    "            concepts = concepts.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model.concept_predictor(inputs)\n",
    "            \n",
    "            # Get binary predictions\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            # Add to concept-level metrics collection\n",
    "            concept_true.append(concepts.cpu().numpy())\n",
    "            concept_pred.append(preds.cpu().numpy())\n",
    "            \n",
    "            # Calculate prediction-level accuracy (all concepts must be correct)\n",
    "            batch_size = concepts.size(0)\n",
    "            for i in range(batch_size):\n",
    "                # Check if all concepts match for this sample\n",
    "                sample_match = torch.all(preds[i] == concepts[i]).item()\n",
    "                sample_correct.append(sample_match)\n",
    "                \n",
    "            # Update counters\n",
    "            all_predictions += batch_size\n",
    "            all_correct_predictions += torch.sum(torch.all(preds == concepts, dim=1)).item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    prediction_accuracy = all_correct_predictions / all_predictions\n",
    "    \n",
    "    # Calculate per-concept metrics\n",
    "    concept_true = np.vstack(concept_true)\n",
    "    concept_pred = np.vstack(concept_pred)\n",
    "    \n",
    "    # Per-concept accuracy (as currently reported)\n",
    "    concept_accuracy = np.mean((concept_true == concept_pred).flatten())\n",
    "    \n",
    "    # Per-concept precision, recall, F1\n",
    "    precision = precision_score(concept_true.flatten(), concept_pred.flatten(), zero_division=0)\n",
    "    recall = recall_score(concept_true.flatten(), concept_pred.flatten(), zero_division=0)\n",
    "    f1 = f1_score(concept_true.flatten(), concept_pred.flatten(), zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'prediction_accuracy': prediction_accuracy,\n",
    "        'concept_accuracy': concept_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'sample_correct': sample_correct\n",
    "    }\n",
    "\n",
    "# Run evaluation for both models\n",
    "print(\"Evaluating baseline CBM...\")\n",
    "baseline_results = evaluate_prediction_level_accuracy(baseline_cbm, test_loader, baseline_cbm_config.device)\n",
    "\n",
    "print(\"Evaluating fuzzy CBM...\")\n",
    "fuzzy_results = evaluate_prediction_level_accuracy(fuzzy_cbm, test_loader, fuzzy_cbm_config.device)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(f\"Baseline CBM:\")\n",
    "print(f\"  Per-prediction accuracy (all concepts correct): {baseline_results['prediction_accuracy']:.4f}\")\n",
    "print(f\"  Per-concept accuracy (as reported before): {baseline_results['concept_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {baseline_results['precision']:.4f}\")\n",
    "print(f\"  Recall: {baseline_results['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {baseline_results['f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nFuzzy CBM:\")\n",
    "print(f\"  Per-prediction accuracy (all concepts correct): {fuzzy_results['prediction_accuracy']:.4f}\")\n",
    "print(f\"  Per-concept accuracy (as reported before): {fuzzy_results['concept_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {fuzzy_results['precision']:.4f}\")\n",
    "print(f\"  Recall: {fuzzy_results['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {fuzzy_results['f1']:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "prediction_improvement = fuzzy_results['prediction_accuracy'] - baseline_results['prediction_accuracy']\n",
    "concept_improvement = fuzzy_results['concept_accuracy'] - baseline_results['concept_accuracy']\n",
    "\n",
    "print(f\"\\nImprovement with Fuzzy Loss:\")\n",
    "print(f\"  Per-prediction accuracy: {prediction_improvement:.4f} ({prediction_improvement*100:.2f}%)\")\n",
    "print(f\"  Per-concept accuracy: {concept_improvement:.4f} ({concept_improvement*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b147b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- All concepts\n",
      "   - All colors\n",
      "      - Main colors\n",
      "         - Border colors\n",
      "         - Arrow symbols\n",
      "            - All symbols\n",
      "               - General symbols\n",
      "               - Curve symbols\n",
      "               - Warning concepts\n",
      "                  - Warning symbols\n",
      "                  - All shapes\n",
      "               - Regulatory signs\n"
     ]
    }
   ],
   "source": [
    "# loading the predefined rule checker that constructs a graph of the concept groups and assigns rules on top of them\n",
    "from rule_eval import construct_full_graph\n",
    "rule_checker = construct_full_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bdc7cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_round']\n",
      "Constraint violated: General color constraint\n",
      "Violating concept names: []\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: []\n",
      "Constraint violated: Main color constraint\n",
      "Violating concept names: []\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_white']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: []\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_white']\n",
      "Constraint violated: Symbols constraint\n",
      "Violating concept names: ['number_8', 'symbol_car', 'symbol_truck', 'symbol_diagonal_stripes']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_white', 'border_color_red']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: []\n",
      "Constraint violated: Symbols constraint\n",
      "Violating concept names: ['number_8', 'symbol_car', 'symbol_truck', 'symbol_diagonal_stripes']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Number of flagged indices in semantic graph: 12\n"
     ]
    }
   ],
   "source": [
    "# evaluating the rules violations on the test set of the fuzzy CBM\n",
    "counter_graph_semantic_relation_fuzzy = 0\n",
    "flagged_indices_graph_semantic_relation_fuzzy = []\n",
    "constraints_violated_relation_fuzzy = []\n",
    "for i, pred in enumerate(concept_predictions_fuzzy):\n",
    "    violated = rule_checker.check_concept_vector(pred, verbose=True, early_stop=False)\n",
    "    if violated:\n",
    "        counter_graph_semantic_relation_fuzzy+= 1\n",
    "        flagged_indices_graph_semantic_relation_fuzzy.append(i)\n",
    "        constraints_violated_relation_fuzzy.append(violated)\n",
    "\n",
    "# Sanity check for semantic graph\n",
    "print(f\"Number of flagged indices in semantic graph: {len(flagged_indices_graph_semantic_relation_fuzzy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6a81539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_construction_site']\n",
      "Constraint violated: Warning symbols constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_construction_site']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_square']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['shape_triangular']\n",
      "Constraint violated: General color constraint\n",
      "Violating concept names: []\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: []\n",
      "Constraint violated: Main color constraint\n",
      "Violating concept names: []\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_triangular']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main color constraint\n",
      "Violating concept names: ['main_color_white', 'main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Shape constraint\n",
      "Violating concept names: ['shape_round', 'shape_triangular']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: General concept invariant\n",
      "Violating concept names: ['main_color_blue', 'shape_round']\n",
      "Constraint violated: No symbols => 2 colors\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Main blue => arrow (possible OOD)\n",
      "Violating concept names: ['main_color_blue']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_animal', 'symbol_double_curve']\n",
      "Constraint violated: Warning concepts constraint\n",
      "Violating concept names: ['symbol_attention', 'symbol_traffic_lights']\n",
      "Constraint violated: Warning symbols constraint\n",
      "Violating concept names: ['symbol_attention', 'symbol_traffic_lights']\n",
      "Number of flagged indices in semantic graph: 15\n"
     ]
    }
   ],
   "source": [
    "# evaluating the rule violations on the test set of the baseline CBM\n",
    "counter_graph_semantic_relation_baseline = 0\n",
    "flagged_indices_graph_semantic_relation_baseline = []\n",
    "constraints_violated_relation_baseline = []\n",
    "for i, pred in enumerate(concept_predictions_baseline):\n",
    "    violated = rule_checker.check_concept_vector(pred, verbose=True, early_stop=False)\n",
    "    if violated:\n",
    "        counter_graph_semantic_relation_fuzzy+= 1\n",
    "        flagged_indices_graph_semantic_relation_baseline.append(i)\n",
    "        constraints_violated_relation_baseline.append(violated)\n",
    "\n",
    "# Sanity check for semantic graph\n",
    "print(f\"Number of flagged indices in semantic graph: {len(flagged_indices_graph_semantic_relation_baseline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d376fc",
   "metadata": {},
   "source": [
    "#### Loading and testing on the BTS dataset as a near out-of-distribution dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1fc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing seed to ensuring reproducibility\n",
    "seed = 42\n",
    "from config.dataset_config import ConceptDatasetConfig\n",
    "from pathlib import Path\n",
    "\n",
    "# Create BTS dataset configuration\n",
    "bts_config = ConceptDatasetConfig(\n",
    "    name=\"bts\",\n",
    "    n_labels=62,  \n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle_dataset=False,  # For evaluation, typically don't shuffle\n",
    "    pin_memory=True,\n",
    "    data_path=Path(\"../data/raw/BTSD/\"),\n",
    "    val_split=0.2\n",
    "\n",
    ")\n",
    "# Resolve the configuration to validate paths and load concept map\n",
    "bts_config.resolve()\n",
    "\n",
    "# Create the dataset factory\n",
    "from data_access.datasets.BTSFactory import BTSFactory\n",
    "\n",
    "bts_factory = BTSFactory(config=bts_config, seed=seed)\n",
    "bts_factory.set_dataloaders()\n",
    "\n",
    "# Access the dataloaders\n",
    "bts_test_loader = bts_factory.test_dataloader\n",
    "bts_train_loader = bts_factory.train_dataloader\n",
    "bts_val_loader = bts_factory.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08400f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of each sign in the GTSRB and how it is mapped to the BTS. If there is an unambiguous mapping, the value is set to the BST label, otherwise it is -1. \n",
    "labels_id_GTS_to_BTS = [-1,-1,-1,-1,-1,-1,-1,-1,-1,31,-1,17,61,19,21,28,25,22,13,3,4,5,0,2,16,10,-1,-1,-1,8,-1,-1,-1,-1,-1,34,-1,-1,35,-1,37,-1,-1,]\n",
    "mapping_BTS_to_GTSRB = {i : labels_id_GTS_to_BTS.index(i) for i in labels_id_GTS_to_BTS if i != -1}\n",
    "Belgium_ID_to_Name = {0: \"Bumpy road\",1: \"Bump\",2: \"Slippery road\",3: \"Bend to The left\",4: \"Bend to The right\",5: \"Double curves first to the left\",6: \"Double curves first to the right\",7: \"School zone\",8: \"Bikes can be cross\",9: \"Domestic animal crossing\",10: \"Roadworks\",11: \"Traffic light\",12: \"Gated railroad crossing ahead\",13: \"Caution\",14: \"Road narrows\",15: \"Road narrows on the left\",16: \"Road narrows on the right\",17: \"Intersection with priority\",18: \"Intersection with priority to the right\",19: \"Yield\",20: \"Yield to incoming traffic\",21: \"Stop\",22: \"No entry\",23: \"No entry for cyclists\",24: \"No vehicle over 2t\",25: \"No entry for trucks\",26: \"Width limit\",27: \"Height limit\",28: \"No vehicles\",29: \"No left turn\",30: \"No right turn\",31: \"No overtaking\",32: \"Speed limit\",33: \"Shared path for pedestrians and cyclists\",34: \"Ahead only\",35: \"Right only\",36: \"Ahead and right only\",37: \"Roundabout\",38: \"Cycleway\",39: \"Segregated path for pedestrians and cyclists\",40: \"No parking\",41: \"No stopping\",42: \"No parking from the 1st till 15th day of the month\",43: \"No parking from the 16th till last day of the month\",44: \"Priority over oncoming traffic\",45: \"Parking permitted\",46: \"Parking for disabled\",47: \"Parking reserved for motorcycles, cars, vans (< 3.5t) and minibusses\",48: \"Parking reserved for trucks\",49: \"Parking reserved for coaches\",50: \"Parking mandatory on the verge or sidewalk\",51: \"Start of a living street\",52: \"End of living street\",53: \"One-way road\",54: \"Dead end\",55: \"End of roadworks\",56: \"Pedestrian crossing\",57: \"Cyclist and moped crossing\",58: \"Parking lot\",59: \"Hump\",60: \"End of priority road\",61: \"Priority road\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e019c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering BTS datasets to only include unambiguous mappings to GTSRB...\n",
      "Valid BTS labels: [0, 2, 3, 4, 5, 8, 10, 13, 16, 17, 19, 21, 22, 25, 28, 31, 34, 35, 37, 61]\n",
      "Number of valid labels: 20\n",
      "Original BTS test size: 2520\n",
      "Filtered BTS test size: 1016\n",
      "Original BTS train size: 3660\n",
      "Filtered BTS train size: 1334\n",
      "Original BTS val size: 915\n",
      "Filtered BTS val size: 326\n",
      "\n",
      "Filtered dataloaders created successfully!\n",
      "You can now use: bts_test_loader_filtered, bts_train_loader_filtered, bts_val_loader_filtered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Get labels that have unambiguous mapping to GTSRB\n",
    "valid_bts_labels = [i for i in labels_id_GTS_to_BTS if i != -1]\n",
    "\n",
    "def filter_dataset_by_labels(dataset, valid_labels):\n",
    "    \"\"\"Filter dataset to only include samples with labels in valid_labels\"\"\"\n",
    "    valid_indices = []\n",
    "    \n",
    "    # Iterate through the dataset and collect indices with valid labels\n",
    "    for idx in range(len(dataset)):\n",
    "        idx, _, label = dataset[idx]  # Unpack: (idx, image, (concepts, label))\n",
    "        if label in valid_labels:\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    return Subset(dataset, valid_indices)\n",
    "\n",
    "# Filter the BTS datasets\n",
    "print(\"Filtering BTS datasets to only include unambiguous mappings to GTSRB...\")\n",
    "print(f\"Valid BTS labels: {sorted(valid_bts_labels)}\")\n",
    "print(f\"Number of valid labels: {len(valid_bts_labels)}\")\n",
    "\n",
    "# Filter test dataset\n",
    "bts_test_filtered = filter_dataset_by_labels(bts_factory.test_dataset, valid_bts_labels)\n",
    "print(f\"Original BTS test size: {len(bts_factory.test_dataset)}\")\n",
    "print(f\"Filtered BTS test size: {len(bts_test_filtered)}\")\n",
    "\n",
    "# Filter train dataset\n",
    "bts_train_filtered = filter_dataset_by_labels(bts_factory.train_dataset, valid_bts_labels)\n",
    "print(f\"Original BTS train size: {len(bts_factory.train_dataset)}\")\n",
    "print(f\"Filtered BTS train size: {len(bts_train_filtered)}\")\n",
    "\n",
    "# Filter validation dataset\n",
    "bts_val_filtered = filter_dataset_by_labels(bts_factory.val_dataset, valid_bts_labels)\n",
    "print(f\"Original BTS val size: {len(bts_factory.val_dataset)}\")\n",
    "print(f\"Filtered BTS val size: {len(bts_val_filtered)}\")\n",
    "\n",
    "# Create new dataloaders with filtered datasets\n",
    "bts_test_loader_filtered = DataLoader(\n",
    "    bts_test_filtered,\n",
    "    batch_size=bts_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=bts_config.num_workers,\n",
    "    pin_memory=bts_config.pin_memory\n",
    ")\n",
    "\n",
    "bts_train_loader_filtered = DataLoader(\n",
    "    bts_train_filtered,\n",
    "    batch_size=bts_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=bts_config.num_workers,\n",
    "    pin_memory=bts_config.pin_memory\n",
    ")\n",
    "\n",
    "bts_val_loader_filtered = DataLoader(\n",
    "    bts_val_filtered,\n",
    "    batch_size=bts_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=bts_config.num_workers,\n",
    "    pin_memory=bts_config.pin_memory\n",
    ")\n",
    "\n",
    "print(\"\\nFiltered dataloaders created successfully!\")\n",
    "print(f\"You can now use: bts_test_loader_filtered, bts_train_loader_filtered, bts_val_loader_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17521344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for Fuzzy CBM on BTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting BTS predictions:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting BTS predictions: 100%|██████████| 16/16 [00:01<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy CBM BTS predictions shape: (1016, 43)\n",
      "Number of BTS samples: 1016\n",
      "\n",
      "Getting predictions for Baseline CBM on BTS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting BTS predictions: 100%|██████████| 16/16 [00:02<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CBM BTS predictions shape: (1016, 43)\n",
      "Number of BTS samples: 1016\n",
      "\n",
      "✓ Both models processed the same BTS test set successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_bts_predictions(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Get concept predictions for BTS dataset (which doesn't have ground truth concepts).\n",
    "    \n",
    "    Args:\n",
    "        model: The CBM model to evaluate\n",
    "        dataloader: DataLoader for BTS dataset (returns idx, image, label)\n",
    "        device: Device to run computations on\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (all_logits, concept_predictions, labels, concept_probabilities)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_logits = []\n",
    "    concept_predictions = []\n",
    "    concept_probabilities = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(dataloader, desc=\"Getting BTS predictions\"):\n",
    "            # BTS dataset returns (idx, image, label) - no concepts\n",
    "            if len(batch_data) == 3:\n",
    "                idx, inputs, labels = batch_data\n",
    "            else:\n",
    "                # In case it's wrapped differently\n",
    "                idx, inputs, (_, labels) = batch_data\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Forward pass through concept predictor\n",
    "            outputs = model.concept_predictor(inputs)\n",
    "            \n",
    "            # Get probabilities and binary predictions\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            # Store results\n",
    "            all_logits.append(outputs.cpu().numpy())\n",
    "            concept_predictions.append(preds.cpu().numpy())\n",
    "            concept_probabilities.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy() if isinstance(labels, torch.Tensor) else labels)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_logits = np.vstack(all_logits)\n",
    "    concept_predictions = np.vstack(concept_predictions)\n",
    "    concept_probabilities = np.vstack(concept_probabilities)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    return all_logits, concept_predictions, all_labels, concept_probabilities\n",
    "\n",
    "# Get predictions for both models on BTS dataset\n",
    "print(\"Getting predictions for Fuzzy CBM on BTS...\")\n",
    "all_logits_fuzzy_bts, concept_predictions_fuzzy_bts, labels_fuzzy_bts, concept_probabilities_fuzzy_bts = \\\n",
    "    get_bts_predictions(fuzzy_cbm, bts_test_loader_filtered, fuzzy_cbm_config.device)\n",
    "\n",
    "print(f\"Fuzzy CBM BTS predictions shape: {concept_predictions_fuzzy_bts.shape}\")\n",
    "print(f\"Number of BTS samples: {len(labels_fuzzy_bts)}\")\n",
    "\n",
    "print(\"\\nGetting predictions for Baseline CBM on BTS...\")\n",
    "all_logits_baseline_bts, concept_predictions_baseline_bts, labels_baseline_bts, concept_probabilities_baseline_bts = \\\n",
    "    get_bts_predictions(baseline_cbm, bts_test_loader_filtered, baseline_cbm_config.device)\n",
    "\n",
    "print(f\"Baseline CBM BTS predictions shape: {concept_predictions_baseline_bts.shape}\")\n",
    "print(f\"Number of BTS samples: {len(labels_baseline_bts)}\")\n",
    "\n",
    "# Verify both models processed the same data\n",
    "assert np.array_equal(labels_fuzzy_bts, labels_baseline_bts), \"Labels mismatch between models!\"\n",
    "print(\"\\n✓ Both models processed the same BTS test set successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48fb255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FUZZY LOSS ANALYSIS ON BTS DATASET\n",
      "================================================================================\n",
      "\n",
      "Fuzzy CBM on BTS Dataset:\n",
      "  Standard BCE Loss:    0.0002277495\n",
      "  Fuzzy Rules Loss:     1.5115638971\n",
      "  Total Loss:           1.5117916467\n",
      "\n",
      "  Individual Rule Violations:\n",
      "    at_most_one_border_colour     : 0.0000383665 ( 0.00% of fuzzy loss)\n",
      "    exactly_one_main_colour       : 0.7504361272 (49.65% of fuzzy loss)\n",
      "    exactly_one_shape             : 0.7500138879 (49.62% of fuzzy loss)\n",
      "    at_most_one_warning           : 0.0007586933 ( 0.05% of fuzzy loss)\n",
      "    no_symbols_exactly_two_colours: 0.0103128115 ( 0.68% of fuzzy loss)\n",
      "    warning_sign_exclusivity      : 0.0000040797 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_main_white    : 0.0000000027 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_border_red    : 0.0000000062 ( 0.00% of fuzzy loss)\n",
      "\n",
      "Baseline CBM on BTS Dataset:\n",
      "  Standard BCE Loss:    0.0003441266\n",
      "  Fuzzy Rules Loss:     1.5071085691\n",
      "  Total Loss:           1.5074526957\n",
      "\n",
      "  Individual Rule Violations:\n",
      "    at_most_one_border_colour     : 0.0000000935 ( 0.00% of fuzzy loss)\n",
      "    exactly_one_main_colour       : 0.7501800656 (49.78% of fuzzy loss)\n",
      "    exactly_one_shape             : 0.7503016591 (49.78% of fuzzy loss)\n",
      "    at_most_one_warning           : 0.0006513224 ( 0.04% of fuzzy loss)\n",
      "    no_symbols_exactly_two_colours: 0.0059707984 ( 0.40% of fuzzy loss)\n",
      "    warning_sign_exclusivity      : 0.0000033742 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_main_white    : 0.0000005467 ( 0.00% of fuzzy loss)\n",
      "    warning_implies_border_red    : 0.0000005417 ( 0.00% of fuzzy loss)\n",
      "\n",
      "================================================================================\n",
      "BTS DATASET - IMPROVEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Overall Fuzzy Loss Reduction on BTS:\n",
      "  Baseline CBM Fuzzy Loss:  1.5071085691\n",
      "  Fuzzy CBM Fuzzy Loss:     1.5115638971\n",
      "  Absolute Reduction:       -0.0044553280\n",
      "  Relative Reduction:       -0.30%\n",
      "\n",
      "Per-Rule Improvements on BTS:\n",
      "  at_most_one_border_colour     : -0.0000382730 (-40927.73%)\n",
      "  exactly_one_main_colour       : -0.0002560616 ( -0.03%)\n",
      "  exactly_one_shape             : 0.0002877712 ( +0.04%)\n",
      "  at_most_one_warning           : -0.0001073710 (-16.49%)\n",
      "  no_symbols_exactly_two_colours: -0.0043420130 (-72.72%)\n",
      "  warning_sign_exclusivity      : -0.0000007054 (-20.91%)\n",
      "  warning_implies_main_white    : 0.0000005440 (+99.51%)\n",
      "  warning_implies_border_red    : 0.0000005354 (+98.85%)\n",
      "\n",
      "================================================================================\n",
      "CROSS-DATASET COMPARISON: GTSRB vs BTS\n",
      "================================================================================\n",
      "\n",
      "Dataset  Baseline Fuzzy Loss  Fuzzy CBM Fuzzy Loss  Absolute Reduction  Relative Reduction (%)\n",
      "  GTSRB             1.513347              1.513074            0.000273                0.018052\n",
      "    BTS             1.507109              1.511564           -0.004455               -0.295621\n",
      "\n",
      "================================================================================\n",
      "PER-RULE COMPARISON: GTSRB vs BTS\n",
      "================================================================================\n",
      "\n",
      "                          Rule  GTSRB Baseline  GTSRB Fuzzy CBM  BTS Baseline  BTS Fuzzy CBM  GTSRB Improvement %  BTS Improvement %\n",
      "    warning_implies_main_white    1.081142e-07     2.784382e-10  5.467083e-07   2.698636e-09            99.742459          99.506385\n",
      "    warning_implies_border_red    3.040026e-07     1.294973e-08  5.416631e-07   6.218595e-09            95.740255          98.851944\n",
      "             exactly_one_shape    7.501136e-01     7.500491e-01  7.503017e-01   7.500139e-01             0.008589           0.038354\n",
      "       exactly_one_main_colour    7.500881e-01     7.500559e-01  7.501801e-01   7.504361e-01             0.004296          -0.034133\n",
      "           at_most_one_warning    1.210499e-02     1.187649e-02  6.513224e-04   7.586933e-04             1.887652         -16.485071\n",
      "      warning_sign_exclusivity    4.639718e-04     4.635207e-04  3.374225e-06   4.079666e-06             0.097220         -20.906747\n",
      "no_symbols_exactly_two_colours    5.755201e-04     6.275345e-04  5.970798e-03   1.031281e-02            -9.037807         -72.720811\n",
      "     at_most_one_border_colour    8.133698e-07     1.601907e-06  9.351358e-08   3.836650e-05           -96.946910      -40927.728158\n",
      "\n",
      "================================================================================\n",
      "SUMMARY - FUZZY LOSS ON BTS DATASET\n",
      "================================================================================\n",
      "\n",
      "Key Findings:\n",
      "  1. Fuzzy loss reduction on GTSRB: 0.02%\n",
      "  2. Fuzzy loss reduction on BTS:   -0.30%\n",
      "\n",
      "⚠ The Fuzzy CBM shows less improvement on OOD data (BTS) compared to GTSRB\n",
      "\n",
      "Note: BTS analysis uses predicted concepts as pseudo ground truth since\n",
      "BTS doesn't have annotated concepts. The fuzzy loss measures internal\n",
      "consistency of predictions with respect to the learned fuzzy rules.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FUZZY LOSS ANALYSIS ON BTS DATASET (without ground truth concepts)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FUZZY LOSS ANALYSIS ON BTS DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Since BTS doesn't have ground truth concepts, we'll evaluate fuzzy loss\n",
    "# using the predicted concepts as if they were ground truth\n",
    "# This shows how well each model adheres to fuzzy rules on OOD data\n",
    "\n",
    "# Convert predictions to tensors\n",
    "all_logits_fuzzy_bts_tensor = torch.tensor(all_logits_fuzzy_bts, dtype=torch.float32)\n",
    "all_logits_baseline_bts_tensor = torch.tensor(all_logits_baseline_bts, dtype=torch.float32)\n",
    "concept_predictions_fuzzy_bts_tensor = torch.tensor(concept_predictions_fuzzy_bts, dtype=torch.float32)\n",
    "concept_predictions_baseline_bts_tensor = torch.tensor(concept_predictions_baseline_bts, dtype=torch.float32)\n",
    "\n",
    "# Calculate fuzzy loss for Fuzzy CBM on BTS\n",
    "# Note: We use predicted concepts as pseudo ground truth to evaluate rule consistency\n",
    "fuzzy_cbm_bts_loss = neutral_fuzzy_loss(all_logits_fuzzy_bts_tensor, concept_predictions_fuzzy_bts_tensor)\n",
    "fuzzy_cbm_bts_standard_loss = neutral_fuzzy_loss.last_standard_loss.item()\n",
    "fuzzy_cbm_bts_fuzzy_loss = neutral_fuzzy_loss.last_fuzzy_loss.item()\n",
    "fuzzy_cbm_bts_total_loss = fuzzy_cbm_bts_standard_loss + fuzzy_cbm_bts_fuzzy_loss\n",
    "fuzzy_cbm_bts_rule_losses = {name: loss.item() for name, loss in neutral_fuzzy_loss.last_individual_losses.items()}\n",
    "\n",
    "print(f\"\\nFuzzy CBM on BTS Dataset:\")\n",
    "print(f\"  Standard BCE Loss:    {fuzzy_cbm_bts_standard_loss:.10f}\")\n",
    "print(f\"  Fuzzy Rules Loss:     {fuzzy_cbm_bts_fuzzy_loss:.10f}\")\n",
    "print(f\"  Total Loss:           {fuzzy_cbm_bts_total_loss:.10f}\")\n",
    "print(f\"\\n  Individual Rule Violations:\")\n",
    "if fuzzy_cbm_bts_fuzzy_loss > 0:\n",
    "    for rule_name, loss in fuzzy_cbm_bts_rule_losses.items():\n",
    "        contribution = (loss / fuzzy_cbm_bts_fuzzy_loss) * 100\n",
    "        print(f\"    {rule_name:30s}: {loss:.10f} ({contribution:5.2f}% of fuzzy loss)\")\n",
    "else:\n",
    "    for rule_name, loss in fuzzy_cbm_bts_rule_losses.items():\n",
    "        print(f\"    {rule_name:30s}: {loss:.10f}\")\n",
    "\n",
    "# Calculate fuzzy loss for Baseline CBM on BTS\n",
    "baseline_cbm_bts_loss = neutral_fuzzy_loss(all_logits_baseline_bts_tensor, concept_predictions_baseline_bts_tensor)\n",
    "baseline_cbm_bts_standard_loss = neutral_fuzzy_loss.last_standard_loss.item()\n",
    "baseline_cbm_bts_fuzzy_loss = neutral_fuzzy_loss.last_fuzzy_loss.item()\n",
    "baseline_cbm_bts_total_loss = baseline_cbm_bts_standard_loss + baseline_cbm_bts_fuzzy_loss\n",
    "baseline_cbm_bts_rule_losses = {name: loss.item() for name, loss in neutral_fuzzy_loss.last_individual_losses.items()}\n",
    "\n",
    "print(f\"\\nBaseline CBM on BTS Dataset:\")\n",
    "print(f\"  Standard BCE Loss:    {baseline_cbm_bts_standard_loss:.10f}\")\n",
    "print(f\"  Fuzzy Rules Loss:     {baseline_cbm_bts_fuzzy_loss:.10f}\")\n",
    "print(f\"  Total Loss:           {baseline_cbm_bts_total_loss:.10f}\")\n",
    "print(f\"\\n  Individual Rule Violations:\")\n",
    "if baseline_cbm_bts_fuzzy_loss > 0:\n",
    "    for rule_name, loss in baseline_cbm_bts_rule_losses.items():\n",
    "        contribution = (loss / baseline_cbm_bts_fuzzy_loss) * 100\n",
    "        print(f\"    {rule_name:30s}: {loss:.10f} ({contribution:5.2f}% of fuzzy loss)\")\n",
    "else:\n",
    "    for rule_name, loss in baseline_cbm_bts_rule_losses.items():\n",
    "        print(f\"    {rule_name:30s}: {loss:.10f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON AND IMPROVEMENT ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BTS DATASET - IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fuzzy_loss_reduction_bts = baseline_cbm_bts_fuzzy_loss - fuzzy_cbm_bts_fuzzy_loss\n",
    "fuzzy_loss_reduction_pct_bts = (fuzzy_loss_reduction_bts / baseline_cbm_bts_fuzzy_loss * 100) if baseline_cbm_bts_fuzzy_loss > 0 else 0\n",
    "\n",
    "print(f\"\\nOverall Fuzzy Loss Reduction on BTS:\")\n",
    "print(f\"  Baseline CBM Fuzzy Loss:  {baseline_cbm_bts_fuzzy_loss:.10f}\")\n",
    "print(f\"  Fuzzy CBM Fuzzy Loss:     {fuzzy_cbm_bts_fuzzy_loss:.10f}\")\n",
    "print(f\"  Absolute Reduction:       {fuzzy_loss_reduction_bts:.10f}\")\n",
    "print(f\"  Relative Reduction:       {fuzzy_loss_reduction_pct_bts:.2f}%\")\n",
    "\n",
    "print(f\"\\nPer-Rule Improvements on BTS:\")\n",
    "for rule_name in baseline_cbm_bts_rule_losses.keys():\n",
    "    baseline_loss = baseline_cbm_bts_rule_losses[rule_name]\n",
    "    fuzzy_loss = fuzzy_cbm_bts_rule_losses[rule_name]\n",
    "    improvement = baseline_loss - fuzzy_loss\n",
    "    improvement_pct = (improvement / baseline_loss * 100) if baseline_loss > 0 else 0\n",
    "    print(f\"  {rule_name:30s}: {improvement:.10f} ({improvement_pct:+6.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CROSS-DATASET COMPARISON (GTSRB vs BTS)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-DATASET COMPARISON: GTSRB vs BTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Dataset': ['GTSRB', 'BTS'],\n",
    "    'Baseline Fuzzy Loss': [baseline_fuzzy_metrics['fuzzy_loss'], baseline_cbm_bts_fuzzy_loss],\n",
    "    'Fuzzy CBM Fuzzy Loss': [fuzzy_cbm_metrics['fuzzy_loss'], fuzzy_cbm_bts_fuzzy_loss],\n",
    "    'Absolute Reduction': [\n",
    "        baseline_fuzzy_metrics['fuzzy_loss'] - fuzzy_cbm_metrics['fuzzy_loss'],\n",
    "        fuzzy_loss_reduction_bts\n",
    "    ],\n",
    "    'Relative Reduction (%)': [\n",
    "        (baseline_fuzzy_metrics['fuzzy_loss'] - fuzzy_cbm_metrics['fuzzy_loss']) / baseline_fuzzy_metrics['fuzzy_loss'] * 100,\n",
    "        fuzzy_loss_reduction_pct_bts\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_cross_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + df_cross_comparison.to_string(index=False))\n",
    "\n",
    "# Per-rule comparison across datasets\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-RULE COMPARISON: GTSRB vs BTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rule_cross_comparison = []\n",
    "for rule_name in baseline_fuzzy_metrics['rule_losses'].keys():\n",
    "    rule_cross_comparison.append({\n",
    "        'Rule': rule_name,\n",
    "        'GTSRB Baseline': baseline_fuzzy_metrics['rule_losses'][rule_name],\n",
    "        'GTSRB Fuzzy CBM': fuzzy_cbm_metrics['rule_losses'][rule_name],\n",
    "        'BTS Baseline': baseline_cbm_bts_rule_losses[rule_name],\n",
    "        'BTS Fuzzy CBM': fuzzy_cbm_bts_rule_losses[rule_name],\n",
    "        'GTSRB Improvement %': ((baseline_fuzzy_metrics['rule_losses'][rule_name] - fuzzy_cbm_metrics['rule_losses'][rule_name]) / baseline_fuzzy_metrics['rule_losses'][rule_name] * 100) if baseline_fuzzy_metrics['rule_losses'][rule_name] > 0 else 0,\n",
    "        'BTS Improvement %': ((baseline_cbm_bts_rule_losses[rule_name] - fuzzy_cbm_bts_rule_losses[rule_name]) / baseline_cbm_bts_rule_losses[rule_name] * 100) if baseline_cbm_bts_rule_losses[rule_name] > 0 else 0\n",
    "    })\n",
    "\n",
    "df_rule_cross_comparison = pd.DataFrame(rule_cross_comparison)\n",
    "df_rule_cross_comparison = df_rule_cross_comparison.sort_values('BTS Improvement %', ascending=False)\n",
    "print(\"\\n\" + df_rule_cross_comparison.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY - FUZZY LOSS ON BTS DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  1. Fuzzy loss reduction on GTSRB: {fuzzy_loss_reduction_pct:.2f}%\")\n",
    "print(f\"  2. Fuzzy loss reduction on BTS:   {fuzzy_loss_reduction_pct_bts:.2f}%\")\n",
    "\n",
    "if fuzzy_loss_reduction_pct_bts > 0:\n",
    "    print(f\"\\n✓ The Fuzzy CBM maintains better logical consistency on OOD data (BTS)\")\n",
    "    print(f\"  This suggests that fuzzy loss training improves generalization of logical rules\")\n",
    "else:\n",
    "    print(f\"\\n⚠ The Fuzzy CBM shows less improvement on OOD data (BTS) compared to GTSRB\")\n",
    "\n",
    "print(f\"\\nNote: BTS analysis uses predicted concepts as pseudo ground truth since\")\n",
    "print(f\"BTS doesn't have annotated concepts. The fuzzy loss measures internal\")\n",
    "print(f\"consistency of predictions with respect to the learned fuzzy rules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af3cb14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RULE VIOLATION ANALYSIS - GTSRB AND BTS DATASETS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANALYZING RULE VIOLATIONS ON GTSRB TEST SET\n",
      "================================================================================\n",
      "\n",
      "Analyzing Baseline CBM on GTSRB...\n",
      "Analyzing Fuzzy CBM on GTSRB...\n",
      "\n",
      "Baseline CBM on GTSRB:\n",
      "  Total samples:        12630\n",
      "  Samples with violations: 15\n",
      "  Violation rate:       0.12%\n",
      "\n",
      "Fuzzy CBM on GTSRB:\n",
      "  Total samples:        12630\n",
      "  Samples with violations: 12\n",
      "  Violation rate:       0.10%\n",
      "\n",
      "================================================================================\n",
      "ANALYZING RULE VIOLATIONS ON BTS TEST SET\n",
      "================================================================================\n",
      "\n",
      "Analyzing Baseline CBM on BTS...\n",
      "Analyzing Fuzzy CBM on BTS...\n",
      "\n",
      "Baseline CBM on BTS:\n",
      "  Total samples:        1016\n",
      "  Samples with violations: 9\n",
      "  Violation rate:       0.89%\n",
      "\n",
      "Fuzzy CBM on BTS:\n",
      "  Total samples:        1016\n",
      "  Samples with violations: 11\n",
      "  Violation rate:       1.08%\n",
      "\n",
      "================================================================================\n",
      "VIOLATION RATE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset        Model  Violation Rate (%)  Violations  Total Samples\n",
      "  GTSRB Baseline CBM            0.118765          15          12630\n",
      "  GTSRB    Fuzzy CBM            0.095012          12          12630\n",
      "    BTS Baseline CBM            0.885827           9           1016\n",
      "    BTS    Fuzzy CBM            1.082677          11           1016\n",
      "\n",
      "================================================================================\n",
      "IMPROVEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "GTSRB Dataset:\n",
      "  Baseline violation rate:  0.12%\n",
      "  Fuzzy CBM violation rate: 0.10%\n",
      "  Improvement:              0.02 percentage points\n",
      "  Relative improvement:     20.00%\n",
      "\n",
      "BTS Dataset:\n",
      "  Baseline violation rate:  0.89%\n",
      "  Fuzzy CBM violation rate: 1.08%\n",
      "  Improvement:              -0.20 percentage points\n",
      "  Relative improvement:     -22.22%\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION ANALYSIS - GTSRB\n",
      "================================================================================\n",
      "\n",
      "                       Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      "Main blue => arrow (possible OOD)               9                4            5      55.555556\n",
      "           No symbols => 2 colors               9                6            3      33.333333\n",
      "      Warning concepts constraint               5                3            2      40.000000\n",
      "       Warning symbols constraint               2                0            2     100.000000\n",
      "            Main color constraint               2                1            1      50.000000\n",
      "         General color constraint               1                1            0       0.000000\n",
      "        General concept invariant               7                7            0       0.000000\n",
      "                 Shape constraint               2                2            0       0.000000\n",
      "               Symbols constraint               0                2           -2       0.000000\n",
      "\n",
      "================================================================================\n",
      "PER-CONSTRAINT VIOLATION ANALYSIS - BTS\n",
      "================================================================================\n",
      "\n",
      "                       Constraint  Baseline Count  Fuzzy CBM Count  Improvement  Improvement %\n",
      "      Warning concepts constraint               1                0            1     100.000000\n",
      "                 Shape constraint               1                0            1     100.000000\n",
      "       Warning symbols constraint               1                0            1     100.000000\n",
      "        General concept invariant               7               11           -4     -57.142857\n",
      "Main blue => arrow (possible OOD)               7               11           -4     -57.142857\n",
      "           No symbols => 2 colors               7               11           -4     -57.142857\n",
      "\n",
      "================================================================================\n",
      "CROSS-DATASET CONSTRAINT COMPARISON\n",
      "================================================================================\n",
      "\n",
      "                       Constraint  GTSRB Baseline  GTSRB Fuzzy  BTS Baseline  BTS Fuzzy  GTSRB Improvement  BTS Improvement\n",
      "         General color constraint               1            1             0          0                  0                0\n",
      "        General concept invariant               7            7             7         11                  0               -4\n",
      "Main blue => arrow (possible OOD)               9            4             7         11                  5               -4\n",
      "            Main color constraint               2            1             0          0                  1                0\n",
      "           No symbols => 2 colors               9            6             7         11                  3               -4\n",
      "                 Shape constraint               2            2             1          0                  0                1\n",
      "               Symbols constraint               0            2             0          0                 -2                0\n",
      "      Warning concepts constraint               5            3             1          0                  2                1\n",
      "       Warning symbols constraint               2            0             1          0                  2                1\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY - RULE VIOLATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Key Findings:\n",
      "  1. GTSRB violation rate reduction: 0.02 percentage points (20.00%)\n",
      "  2. BTS violation rate reduction:   -0.20 percentage points (-22.22%)\n",
      "\n",
      "✓ Fuzzy CBM shows improved rule adherence on GTSRB\n",
      "⚠ Limited improvement on OOD data (BTS)\n",
      "\n",
      "Most improved constraints on GTSRB:\n",
      "  - Main blue => arrow (possible OOD): 5 fewer violations (55.6%)\n",
      "  - No symbols => 2 colors: 3 fewer violations (33.3%)\n",
      "  - Warning concepts constraint: 2 fewer violations (40.0%)\n",
      "\n",
      "Most improved constraints on BTS:\n",
      "  - Warning concepts constraint: 1 fewer violations (100.0%)\n",
      "  - Shape constraint: 1 fewer violations (100.0%)\n",
      "  - Warning symbols constraint: 1 fewer violations (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RULE VIOLATION ANALYSIS USING RULE CHECKER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RULE VIOLATION ANALYSIS - GTSRB AND BTS DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_rule_violations(concept_predictions, dataset_name, model_name):\n",
    "    \"\"\"\n",
    "    Analyze rule violations for a given set of concept predictions.\n",
    "    \n",
    "    Args:\n",
    "        concept_predictions: numpy array of concept predictions\n",
    "        dataset_name: name of the dataset (e.g., \"GTSRB\", \"BTS\")\n",
    "        model_name: name of the model (e.g., \"Baseline CBM\", \"Fuzzy CBM\")\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing violation statistics\n",
    "    \"\"\"\n",
    "    total_violations = 0\n",
    "    flagged_indices = []\n",
    "    violated_constraints = []\n",
    "    constraint_counts = defaultdict(int)\n",
    "    \n",
    "    for i, pred in enumerate(concept_predictions):\n",
    "        violations = rule_checker.check_concept_vector(pred.astype(int), verbose=False, early_stop=False)\n",
    "        if violations:\n",
    "            total_violations += 1\n",
    "            flagged_indices.append(i)\n",
    "            violated_constraints.append(violations)\n",
    "            \n",
    "            # Count each constraint violation\n",
    "            for violation in violations:\n",
    "                constraint_counts[violation['constraint']] += 1\n",
    "    \n",
    "    violation_rate = (total_violations / len(concept_predictions)) * 100\n",
    "    \n",
    "    return {\n",
    "        'dataset': dataset_name,\n",
    "        'model': model_name,\n",
    "        'total_samples': len(concept_predictions),\n",
    "        'total_violations': total_violations,\n",
    "        'violation_rate': violation_rate,\n",
    "        'flagged_indices': flagged_indices,\n",
    "        'violated_constraints': violated_constraints,\n",
    "        'constraint_counts': dict(constraint_counts)\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYZE VIOLATIONS ON GTSRB\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING RULE VIOLATIONS ON GTSRB TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze Baseline CBM on GTSRB\n",
    "print(\"\\nAnalyzing Baseline CBM on GTSRB...\")\n",
    "baseline_gtsrb_violations = analyze_rule_violations(\n",
    "    concept_predictions_baseline, \n",
    "    \"GTSRB\", \n",
    "    \"Baseline CBM\"\n",
    ")\n",
    "\n",
    "# Analyze Fuzzy CBM on GTSRB\n",
    "print(\"Analyzing Fuzzy CBM on GTSRB...\")\n",
    "fuzzy_gtsrb_violations = analyze_rule_violations(\n",
    "    concept_predictions_fuzzy, \n",
    "    \"GTSRB\", \n",
    "    \"Fuzzy CBM\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline CBM on GTSRB:\")\n",
    "print(f\"  Total samples:        {baseline_gtsrb_violations['total_samples']}\")\n",
    "print(f\"  Samples with violations: {baseline_gtsrb_violations['total_violations']}\")\n",
    "print(f\"  Violation rate:       {baseline_gtsrb_violations['violation_rate']:.2f}%\")\n",
    "\n",
    "print(f\"\\nFuzzy CBM on GTSRB:\")\n",
    "print(f\"  Total samples:        {fuzzy_gtsrb_violations['total_samples']}\")\n",
    "print(f\"  Samples with violations: {fuzzy_gtsrb_violations['total_violations']}\")\n",
    "print(f\"  Violation rate:       {fuzzy_gtsrb_violations['violation_rate']:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# ANALYZE VIOLATIONS ON BTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING RULE VIOLATIONS ON BTS TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze Baseline CBM on BTS\n",
    "print(\"\\nAnalyzing Baseline CBM on BTS...\")\n",
    "baseline_bts_violations = analyze_rule_violations(\n",
    "    concept_predictions_baseline_bts, \n",
    "    \"BTS\", \n",
    "    \"Baseline CBM\"\n",
    ")\n",
    "\n",
    "# Analyze Fuzzy CBM on BTS\n",
    "print(\"Analyzing Fuzzy CBM on BTS...\")\n",
    "fuzzy_bts_violations = analyze_rule_violations(\n",
    "    concept_predictions_fuzzy_bts, \n",
    "    \"BTS\", \n",
    "    \"Fuzzy CBM\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline CBM on BTS:\")\n",
    "print(f\"  Total samples:        {baseline_bts_violations['total_samples']}\")\n",
    "print(f\"  Samples with violations: {baseline_bts_violations['total_violations']}\")\n",
    "print(f\"  Violation rate:       {baseline_bts_violations['violation_rate']:.2f}%\")\n",
    "\n",
    "print(f\"\\nFuzzy CBM on BTS:\")\n",
    "print(f\"  Total samples:        {fuzzy_bts_violations['total_samples']}\")\n",
    "print(f\"  Samples with violations: {fuzzy_bts_violations['total_violations']}\")\n",
    "print(f\"  Violation rate:       {fuzzy_bts_violations['violation_rate']:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VIOLATION RATE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "violation_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Dataset': 'GTSRB',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_gtsrb_violations['violation_rate'],\n",
    "        'Violations': baseline_gtsrb_violations['total_violations'],\n",
    "        'Total Samples': baseline_gtsrb_violations['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'GTSRB',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_gtsrb_violations['violation_rate'],\n",
    "        'Violations': fuzzy_gtsrb_violations['total_violations'],\n",
    "        'Total Samples': fuzzy_gtsrb_violations['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'BTS',\n",
    "        'Model': 'Baseline CBM',\n",
    "        'Violation Rate (%)': baseline_bts_violations['violation_rate'],\n",
    "        'Violations': baseline_bts_violations['total_violations'],\n",
    "        'Total Samples': baseline_bts_violations['total_samples']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'BTS',\n",
    "        'Model': 'Fuzzy CBM',\n",
    "        'Violation Rate (%)': fuzzy_bts_violations['violation_rate'],\n",
    "        'Violations': fuzzy_bts_violations['total_violations'],\n",
    "        'Total Samples': fuzzy_bts_violations['total_samples']\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + violation_summary.to_string(index=False))\n",
    "\n",
    "# Calculate improvements\n",
    "gtsrb_improvement = baseline_gtsrb_violations['violation_rate'] - fuzzy_gtsrb_violations['violation_rate']\n",
    "bts_improvement = baseline_bts_violations['violation_rate'] - fuzzy_bts_violations['violation_rate']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nGTSRB Dataset:\")\n",
    "print(f\"  Baseline violation rate:  {baseline_gtsrb_violations['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_gtsrb_violations['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {gtsrb_improvement:.2f} percentage points\")\n",
    "print(f\"  Relative improvement:     {(gtsrb_improvement / baseline_gtsrb_violations['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nBTS Dataset:\")\n",
    "print(f\"  Baseline violation rate:  {baseline_bts_violations['violation_rate']:.2f}%\")\n",
    "print(f\"  Fuzzy CBM violation rate: {fuzzy_bts_violations['violation_rate']:.2f}%\")\n",
    "print(f\"  Improvement:              {bts_improvement:.2f} percentage points\")\n",
    "print(f\"  Relative improvement:     {(bts_improvement / baseline_bts_violations['violation_rate'] * 100):.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# PER-CONSTRAINT VIOLATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION ANALYSIS - GTSRB\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all constraint names from both models\n",
    "all_constraints_gtsrb = set(baseline_gtsrb_violations['constraint_counts'].keys()) | \\\n",
    "                        set(fuzzy_gtsrb_violations['constraint_counts'].keys())\n",
    "\n",
    "constraint_comparison_gtsrb = []\n",
    "for constraint in sorted(all_constraints_gtsrb):\n",
    "    baseline_count = baseline_gtsrb_violations['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_gtsrb_violations['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_gtsrb.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_gtsrb = pd.DataFrame(constraint_comparison_gtsrb)\n",
    "df_constraint_gtsrb = df_constraint_gtsrb.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_gtsrb.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CONSTRAINT VIOLATION ANALYSIS - BTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all constraint names from both models\n",
    "all_constraints_bts = set(baseline_bts_violations['constraint_counts'].keys()) | \\\n",
    "                      set(fuzzy_bts_violations['constraint_counts'].keys())\n",
    "\n",
    "constraint_comparison_bts = []\n",
    "for constraint in sorted(all_constraints_bts):\n",
    "    baseline_count = baseline_bts_violations['constraint_counts'].get(constraint, 0)\n",
    "    fuzzy_count = fuzzy_bts_violations['constraint_counts'].get(constraint, 0)\n",
    "    improvement = baseline_count - fuzzy_count\n",
    "    improvement_pct = (improvement / baseline_count * 100) if baseline_count > 0 else 0\n",
    "    \n",
    "    constraint_comparison_bts.append({\n",
    "        'Constraint': constraint,\n",
    "        'Baseline Count': baseline_count,\n",
    "        'Fuzzy CBM Count': fuzzy_count,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement_pct\n",
    "    })\n",
    "\n",
    "df_constraint_bts = pd.DataFrame(constraint_comparison_bts)\n",
    "df_constraint_bts = df_constraint_bts.sort_values('Improvement', ascending=False)\n",
    "print(\"\\n\" + df_constraint_bts.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# CROSS-DATASET CONSTRAINT COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-DATASET CONSTRAINT COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_constraints = all_constraints_gtsrb | all_constraints_bts\n",
    "cross_dataset_comparison = []\n",
    "\n",
    "for constraint in sorted(all_constraints):\n",
    "    cross_dataset_comparison.append({\n",
    "        'Constraint': constraint,\n",
    "        'GTSRB Baseline': baseline_gtsrb_violations['constraint_counts'].get(constraint, 0),\n",
    "        'GTSRB Fuzzy': fuzzy_gtsrb_violations['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Baseline': baseline_bts_violations['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Fuzzy': fuzzy_bts_violations['constraint_counts'].get(constraint, 0),\n",
    "        'GTSRB Improvement': baseline_gtsrb_violations['constraint_counts'].get(constraint, 0) - \n",
    "                            fuzzy_gtsrb_violations['constraint_counts'].get(constraint, 0),\n",
    "        'BTS Improvement': baseline_bts_violations['constraint_counts'].get(constraint, 0) - \n",
    "                          fuzzy_bts_violations['constraint_counts'].get(constraint, 0)\n",
    "    })\n",
    "\n",
    "df_cross_dataset = pd.DataFrame(cross_dataset_comparison)\n",
    "print(\"\\n\" + df_cross_dataset.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY - RULE VIOLATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  1. GTSRB violation rate reduction: {gtsrb_improvement:.2f} percentage points ({(gtsrb_improvement / baseline_gtsrb_violations['violation_rate'] * 100):.2f}%)\")\n",
    "print(f\"  2. BTS violation rate reduction:   {bts_improvement:.2f} percentage points ({(bts_improvement / baseline_bts_violations['violation_rate'] * 100):.2f}%)\")\n",
    "\n",
    "if gtsrb_improvement > 0 and bts_improvement > 0:\n",
    "    print(f\"\\n✓ Fuzzy CBM shows improved rule adherence on both GTSRB and BTS datasets\")\n",
    "    print(f\"  This validates that fuzzy loss training successfully enforces logical constraints\")\n",
    "elif gtsrb_improvement > 0:\n",
    "    print(f\"\\n✓ Fuzzy CBM shows improved rule adherence on GTSRB\")\n",
    "    print(f\"⚠ Limited improvement on OOD data (BTS)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Unexpected results - review constraint implementation\")\n",
    "\n",
    "print(f\"\\nMost improved constraints on GTSRB:\")\n",
    "top_improved_gtsrb = df_constraint_gtsrb.head(3)\n",
    "for _, row in top_improved_gtsrb.iterrows():\n",
    "    print(f\"  - {row['Constraint']}: {row['Improvement']} fewer violations ({row['Improvement %']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nMost improved constraints on BTS:\")\n",
    "top_improved_bts = df_constraint_bts.head(3)\n",
    "for _, row in top_improved_bts.iterrows():\n",
    "    print(f\"  - {row['Constraint']}: {row['Improvement']} fewer violations ({row['Improvement %']:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
